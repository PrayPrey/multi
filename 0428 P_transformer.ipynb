{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bentrevett/multi30k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_en= spacy.load(\"en_core_web_sm\")\n",
    "nlp_ge = spacy.load(\"de_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stopwords_ge = spacy.lang.en.stop_words.STOP_WORDS \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 29000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1014\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 (Vocabulary 집) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_en = np.array('')\n",
    "# train_ge = np.array('')\n",
    "\n",
    "# for i,j in zip(tqdm(dataset['train']['en']),dataset['train']['de']):\n",
    "#     train_en = np.append(train_en, np.array([k.text for k in nlp_en(i) if k.text not in list(stopwords_en)]))\n",
    "#     train_ge = np.append(train_ge, np.array([k.text for k in nlp_ge(j) if k.text not in list(stopwords_ge)]))\n",
    "\n",
    "        \n",
    "# valid_en = np.array('')\n",
    "# valid_ge = np.array('')\n",
    "    \n",
    "        \n",
    "# for i,j in zip(tqdm(dataset['validation']['en']),dataset['validation']['de']):\n",
    "#     valid_en = np.append(valid_en, np.array([k.text for k in nlp_en(i) if k.text not in list(stopwords_en)]))\n",
    "#     valid_ge = np.append(valid_ge, np.array([k.text for k in nlp_ge(j) if k.text not in list(stopwords_ge)]))\n",
    "\n",
    "        \n",
    "# test_en = np.array('')\n",
    "# test_ge = np.array('')\n",
    "\n",
    "# for i,j in zip(tqdm(dataset['test']['en']),dataset['test']['de']):\n",
    "#     test_en = np.append(test_en, np.array([k.text for k in nlp_en(i) if k.text not in list(stopwords_en)]))\n",
    "#     test_ge = np.append(test_ge, np.array([k.text for k in nlp_ge(j) if k.text not in list(stopwords_ge)]))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import gzip\n",
    "\n",
    "# # save and compress.\n",
    "# with gzip.open('train_en.pickle', 'wb') as f:\n",
    "#     pickle.dump(train_en, f)\n",
    "# with gzip.open('train_ge.pickle', 'wb') as f:\n",
    "#     pickle.dump(train_ge, f)\n",
    "\n",
    "\n",
    "# # save and compress.\n",
    "# with gzip.open('test_en.pickle', 'wb') as f:\n",
    "#     pickle.dump(test_en, f)\n",
    "# with gzip.open('test_ge.pickle', 'wb') as f:\n",
    "#     pickle.dump(test_ge, f)\n",
    "\n",
    "\n",
    "# # save and compress.\n",
    "# with gzip.open('valid_en.pickle', 'wb') as f:\n",
    "#     pickle.dump(valid_en, f)\n",
    "# with gzip.open('valid_ge.pickle', 'wb') as f:\n",
    "#     pickle.dump(valid_ge, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# load and uncompress.\n",
    "with gzip.open('train_en.pickle','rb') as f:\n",
    "    train_en = pickle.load(f)[1:]\n",
    "with gzip.open('train_ge.pickle','rb') as f:\n",
    "    train_ge = pickle.load(f)[1:]\n",
    "    \n",
    "\n",
    "# load and uncompress.\n",
    "with gzip.open('test_en.pickle','rb') as f:\n",
    "    test_en = pickle.load(f)[1:]\n",
    "with gzip.open('test_ge.pickle','rb') as f:\n",
    "    test_ge = pickle.load(f)[1:]\n",
    "    \n",
    "    \n",
    "# load and uncompress.\n",
    "with gzip.open('valid_en.pickle','rb') as f:\n",
    "    valid_en = pickle.load(f)[1:]\n",
    "with gzip.open('valid_ge.pickle','rb') as f:\n",
    "    valid_ge = pickle.load(f)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = np.append(train_en ,train_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28776"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/587122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 587122/587122 [00:00<00:00, 703824.97it/s]\n"
     ]
    }
   ],
   "source": [
    "ww_dict = {}\n",
    "ww_num_dict = {}\n",
    "num = 4  # 0 : pad / 1 : start / 2 : end / 3 : unk\n",
    "\n",
    "# 정수 인코딩\n",
    "for www in tqdm(train_all):\n",
    "    if www.strip() in ww_dict.keys():\n",
    "        ww_num_dict[www.strip()] += 1\n",
    "        pass\n",
    "    else:\n",
    "        ww_dict[www.strip()] = num\n",
    "        ww_num_dict[www.strip()] = 1\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18c11d33a90>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = sorted(ww_num_dict.values(), reverse = True)\n",
    "\n",
    "# Vocabulary dictionary를 만들 시 Zipf's law를 따라여 어느 정도 중요한 어구를 잘 나타내고 있다고 볼 수 있다.\n",
    "# (그렇지 않으면 해당 token들은 전체 문서의 특성을 잘 못 나타낸다고 볼 수 있다.)\n",
    "# 그림을 그려보니 해당 tokenize는 전체 문서의 특성을 잘 나타내지 못한다고 볼 수 있다.` 말고 다른 것을 사용해보자. : 그냥 Hard하게 하자.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 50\n",
    "M =0\n",
    "max_freq = plot[M]\n",
    "\n",
    "plt.plot(range(0, N), [1/i for i in range(1, N+1)])\n",
    "plt.plot(range(0, N) ,[i/max_freq for i in plot[M:M+N]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28774"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ww_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28774"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(ww_dict.items(),key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 29000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1014\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_en = []\n",
    "# train_data_ge = []\n",
    "\n",
    "# for i,j in zip(tqdm(dataset['train']['en']),dataset['train']['de']):\n",
    "#     train_data_en.append([ww_dict[k.text.strip()] for k in nlp_en(i) if k.text not in list(stopwords_en)])\n",
    "#     train_data_ge.append([ww_dict[k.text.strip()] for k in nlp_ge(j) if k.text not in list(stopwords_ge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_en = []\n",
    "# test_data_ge = []\n",
    "\n",
    "# # train 데이터 기준으로 vocab을 만듦으로 test / valid 데이터에 대해서는 unk을 넣어야 한다.\n",
    "# # 0 : pad / 1 : start / 2 : end / 3 : unk\n",
    "\n",
    "# for i,j in zip(tqdm(dataset['test']['en']),dataset['test']['de']):\n",
    "#     small_lst = []\n",
    "#     for k in nlp_en(i):\n",
    "#         if (k.text in list(stopwords_en)):\n",
    "#             pass\n",
    "#         else:\n",
    "#             if (k.text.strip() in ww_dict.keys()):\n",
    "#                 small_lst.append(ww_dict[k.text.strip()])\n",
    "#             else:\n",
    "#                 small_lst.append(3)    \n",
    "#     test_data_en.append(small_lst)\n",
    "    \n",
    "#     small_lst = []\n",
    "#     for k in nlp_ge(j):\n",
    "#         if (k.text in list(stopwords_ge)):\n",
    "#             pass\n",
    "#         else:\n",
    "#             if (k.text.strip() in ww_dict.keys()):\n",
    "#                 small_lst.append(ww_dict[k.text.strip()])\n",
    "#             else:\n",
    "#                 small_lst.append(3)    \n",
    "#     test_data_ge.append(small_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# valid_data_en = []\n",
    "# valid_data_ge = []\n",
    "\n",
    "# for i,j in zip(tqdm(dataset['validation']['en']),dataset['validation']['de']):\n",
    "    \n",
    "#     small_lst = []\n",
    "#     for k in nlp_en(i):\n",
    "#         if (k.text in list(stopwords_en)):\n",
    "#             pass\n",
    "#         else:\n",
    "#             if (k.text.strip() in ww_dict.keys()):\n",
    "#                 small_lst.append(ww_dict[k.text.strip()])\n",
    "#             else:\n",
    "#                 small_lst.append(3)    \n",
    "#     valid_data_en.append(small_lst)\n",
    "    \n",
    "#     small_lst = []    \n",
    "#     for k in nlp_ge(j):\n",
    "\n",
    "#         if (k.text in list(stopwords_ge)):\n",
    "#             pass\n",
    "#         else:\n",
    "#             if (k.text.strip() in ww_dict.keys()):\n",
    "#                 small_lst.append(ww_dict[k.text.strip()])\n",
    "#             else:\n",
    "#                 small_lst.append(3)    \n",
    "#     valid_data_ge.append(small_lst)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import gzip\n",
    "\n",
    "# # save and compress.\n",
    "# with gzip.open('train_data_en.pickle', 'wb') as f:\n",
    "#     pickle.dump(train_data_en, f)\n",
    "# with gzip.open('train_data_ge.pickle', 'wb') as f:\n",
    "#     pickle.dump(train_data_ge, f)\n",
    "\n",
    "\n",
    "# # save and compress.\n",
    "# with gzip.open('test_data_en.pickle', 'wb') as f:\n",
    "#     pickle.dump(test_data_en, f)\n",
    "# with gzip.open('test_data_ge.pickle', 'wb') as f:\n",
    "#     pickle.dump(test_data_ge, f)\n",
    "\n",
    "\n",
    "# # save and compress.\n",
    "# with gzip.open('valid_data_en.pickle', 'wb') as f:\n",
    "#     pickle.dump(valid_data_en, f)\n",
    "# with gzip.open('valid_data_ge.pickle', 'wb') as f:\n",
    "#     pickle.dump(valid_data_ge, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# load and uncompress.\n",
    "with gzip.open('train_data_en.pickle','rb') as f:\n",
    "    train_data_en = pickle.load(f)[1:]\n",
    "with gzip.open('train_data_ge.pickle','rb') as f:\n",
    "    train_data_ge = pickle.load(f)[1:]\n",
    "    \n",
    "\n",
    "# load and uncompress.\n",
    "with gzip.open('test_data_en.pickle','rb') as f:\n",
    "    test_data_en = pickle.load(f)[1:]\n",
    "with gzip.open('test_data_ge.pickle','rb') as f:\n",
    "    test_data_ge = pickle.load(f)[1:]\n",
    "    \n",
    "    \n",
    "# load and uncompress.\n",
    "with gzip.open('valid_data_en.pickle','rb') as f:\n",
    "    valid_data_en = pickle.load(f)[1:]\n",
    "with gzip.open('valid_data_ge.pickle','rb') as f:\n",
    "    valid_data_ge = pickle.load(f)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences_en(sequences):\n",
    "    max_len = 128\n",
    "    padded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) >= max_len:\n",
    "            padded_sequence = sequence[:max_len-1] + [2]  # 최대 길이까지 잘라냄\n",
    "        else:\n",
    "            padded_sequence = sequence + [2] + [0] * (max_len - len(sequence) - 1)  # 패딩 추가\n",
    "        padded_sequences.append(padded_sequence)\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences_de(sequences):\n",
    "    max_len = 128\n",
    "    padded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) >= max_len:\n",
    "            padded_sequence = [1] + [2] + sequence[:max_len-2]  # 최대 길이까지 잘라냄\n",
    "        else:\n",
    "            padded_sequence = [1] + sequence + [2] + [0] * (max_len - len(sequence) - 2)  # 패딩 추가\n",
    "        padded_sequences.append(padded_sequence)\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_final, train_ge_final = torch.tensor(pad_sequences_en(train_data_en)), torch.tensor(pad_sequences_de(train_data_ge))\n",
    "valid_en_final, valid_ge_final = torch.tensor(pad_sequences_en(valid_data_en)), torch.tensor(pad_sequences_de(valid_data_ge))\n",
    "test_en_final, test_ge_final = torch.tensor(pad_sequences_en(test_data_en)), torch.tensor(pad_sequences_de(test_data_ge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16},\n",
       " {1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  33,\n",
       "  36})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([len(i) for i in train_en]), set([len(i) for i in train_ge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, inputs, output):\n",
    "\n",
    "        self.inputs = inputs\n",
    "        self.output = output\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        inputs = self.inputs[idx]\n",
    "        output = self.output[idx]\n",
    "        \n",
    "        return inputs, output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_en_final, train_ge_final)\n",
    "valid_dataset = Dataset(valid_en_final, valid_ge_final)\n",
    "test_dataset = Dataset(test_en_final, test_ge_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = False, drop_last = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 64, shuffle = False, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, max_len = 128):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pe = self.create_positinal_encoding(max_len, self.d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def create_positinal_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        for pos in range(max_len):  \n",
    "            for i in range(0, d_model, 2):  \n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)  \n",
    "        return pe\n",
    "\n",
    "    def forward(self, encoded_words):\n",
    "        \n",
    "        embedding = self.embed(encoded_words) * torch.sqrt(torch.tensor(self.d_model)).to(device)\n",
    "        embedding += self.pe[:, :embedding.size(1)]   \n",
    "        embedding = self.dropout(embedding)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attention(nn.Module):\n",
    "    \n",
    "#     def __init__(self, embedding_size = 512):\n",
    "        \n",
    "#         self.data = data\n",
    "#         self.embedding_size= embedding_size\n",
    "#         self.weight_Q = nn.Linear(embedding_size, embedding_size)\n",
    "#         self.weight_K = nn.Linear(embedding_size, embedding_size)\n",
    "#         self.weight_V = nn.Linear(embedding_size, embedding_size)\n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "#     def forward(self, data):\n",
    "        \n",
    "#         Q = self.weight_Q(data)\n",
    "#         K = self.weight_K(data)\n",
    "#         V = self.weight_V(data)\n",
    "#         score = torch.matmul(Q,K.T) / torch.sqrt(self.embedding_size)\n",
    "#         value = self.softmax(score) * V\n",
    "#         return value\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inputs, outputs_input, outputs_target):\n",
    "    \n",
    "    def subsequent_mask(size):\n",
    "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype = torch.uint8)\n",
    "        return mask.unsqueeze(0) # 상삼각행렬 생성 -> 행과 열을 뒤 바꾸어 하삼각행렬로 바꿈. (밑에가 다 0)\n",
    "    \n",
    "    inputs_mask = inputs != 0\n",
    "    inputs_mask = inputs_mask.to(device)\n",
    "    inputs_mask = inputs_mask.unsqueeze(1).unsqueeze(1) # 각  input에 대해서 상삼각행렬에 대응하도록 설정.\n",
    "    \n",
    "    outputs_input_mask = outputs_input != 0\n",
    "    outputs_input_mask = outputs_input_mask.unsqueeze(1) \n",
    "    outputs_input_mask = outputs_input_mask & subsequent_mask(outputs_input.size(-1)).type_as(outputs_input_mask.data)\n",
    "    outputs_input_mask = outputs_input_mask.unsqueeze(1)\n",
    "    # masking을 해줌으로서, \n",
    "\n",
    "    \n",
    "    outputs_target_mask = outputs_target != 0\n",
    "    \n",
    "    return inputs_mask, outputs_input_mask, outputs_target_mask\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_en_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key  = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.concat = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, query, key, value, mask):\n",
    "        \n",
    "        query = self.query(query)\n",
    "        key = self.key(key)\n",
    "        value = self.value(value)\n",
    "        \n",
    "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        \n",
    "\n",
    "        scores = torch.matmul(query, key.permute(0 ,1 ,3, 2)) / math.sqrt(query.size(-1))\n",
    "        \n",
    "        # print(query.shape, key.shape, value.shape, mask.shape, scores.shape)\n",
    "\n",
    "        \n",
    "        scores = scores.masked_fill(mask == 0, -1e9) # masking 된 것에 매우 작은 수 부여 -> softmax 계산시 -inf 로 계산되어짐.\n",
    "        weights = F.softmax(scores, dim = -1) # attention score 계산\n",
    "        context = torch.matmul(weights, value)  # attention value 계산\n",
    "        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
    "        \n",
    "        interacted = self.concat(context)\n",
    "        \n",
    "        return interacted\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, middle_dim = 2048):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, embeddings, mask):\n",
    "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
    "        interacted = self.layernorm(interacted + embeddings)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        encoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return encoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.src_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
    "        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n",
    "        query = self.layernorm(query + embeddings)\n",
    "        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n",
    "        interacted = self.layernorm(interacted + query)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        decoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P_Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, vocab_size):\n",
    "        super(P_Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed = Embeddings(self.vocab_size, d_model)\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_words, src_mask):\n",
    "        src_embeddings = self.embed(src_words)\n",
    "        encoded_layers = []\n",
    "        for layer in self.encoder:\n",
    "            src_embeddings = layer(src_embeddings, src_mask)\n",
    "            encoded_layers.append(src_embeddings)\n",
    "            \n",
    "        return encoded_layers\n",
    "\n",
    "    def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
    "        tgt_embeddings = self.embed(target_words)\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            tgt_embeddings = layer(tgt_embeddings, src_embeddings[i], src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "\n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded_layers = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded_layers, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, vocab_size):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed = Embeddings(self.vocab_size, d_model)\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_words, src_mask):\n",
    "        src_embeddings = self.embed(src_words)\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            src_embeddings = layer(src_embeddings, src_mask)\n",
    "            \n",
    "        return src_embeddings\n",
    "\n",
    "    def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
    "        tgt_embeddings = self.embed(target_words)\n",
    "        for layer in self.decoder:\n",
    "            tgt_embeddings = layer(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "\n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamWarmup:\n",
    "    \n",
    "    def __init__(self, model_size, warmup_steps, optimizer):\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        self.current_step = 0\n",
    "        self.lr = 0\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        self.current_step += 1\n",
    "        lr = self.get_lr()\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "        self.lr = lr\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LossWithLS(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, smooth):\n",
    "        super(LossWithLS, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, prediction, target, mask):\n",
    "        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n",
    "        target = target.contiguous().view(-1)   # (batch_size * max_words)\n",
    "        mask = mask.float()\n",
    "        mask = mask.view(-1)       # (batch_size * max_words)\n",
    "        \n",
    "        # Smoothed one-hot labels\n",
    "        labels = torch.full_like(prediction, self.smooth / (self.size - 1))\n",
    "        labels.scatter_(1, target.unsqueeze(1), 1 - self.smooth)\n",
    "        \n",
    "        # Apply mask\n",
    "        masked_prediction = prediction * mask.unsqueeze(1)\n",
    "        masked_labels = labels * mask.unsqueeze(1)\n",
    "\n",
    "        \n",
    "        # Calculate negative log likelihood loss\n",
    "        loss = F.nll_loss(masked_prediction, target, reduction='none')\n",
    "        loss *= mask\n",
    "        \n",
    "        # Normalize the loss\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "heads = 8\n",
    "num_layers = 6\n",
    "num_layers = 6\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "vocab_len = len(ww_dict.keys()) + 4\n",
    "\n",
    "transformer = P_Transformer(d_model = d_model , heads = heads, num_layers = num_layers, vocab_size = vocab_len)\n",
    "transformer = transformer.to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters())\n",
    "transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(vocab_len, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader.dataset))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoon303b\u001b[0m (\u001b[33mku_software\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\USER\\Documents\\Jupyter_Notebook\\Graduate_중앙대\\Second\\wandb\\run-20240428_213310-kk2oawka</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ku_software/P_Transformer_Hard_Coding/runs/kk2oawka' target=\"_blank\">deft-shape-10</a></strong> to <a href='https://wandb.ai/ku_software/P_Transformer_Hard_Coding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ku_software/P_Transformer_Hard_Coding' target=\"_blank\">https://wandb.ai/ku_software/P_Transformer_Hard_Coding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ku_software/P_Transformer_Hard_Coding/runs/kk2oawka' target=\"_blank\">https://wandb.ai/ku_software/P_Transformer_Hard_Coding/runs/kk2oawka</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ku_software/P_Transformer_Hard_Coding/runs/kk2oawka?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x18c80bf0610>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"P_Transformer_Hard_Coding\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"loss\": 'Cross_Entropy_loss',\n",
    "    \"architecture\": \"P_Transformer\",\n",
    "    \"optimizer\" : 'AdamWarmup',\n",
    "    'layer' : 6,\n",
    "    'heads' : 8,\n",
    "    'd_model' : 64   \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def generate_next_words(transformer, sequence, encoded, question_mask, beam_width):\n",
    "    \n",
    "    # pad : 0 / start : 1 / end : 2 / unk : 3\n",
    "    start_token = 1\n",
    "    \n",
    "    if not sequence:\n",
    "        return [(start_token, 0)]\n",
    "    \n",
    "    size = len(sequence)\n",
    "    target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "    target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    words = torch.LongTensor([sequence]).to(device)\n",
    "\n",
    "    decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
    "    predictions = transformer.logit(decoded[:, -1])\n",
    "\n",
    "    # Apply log_softmax\n",
    "    log_probs = F.log_softmax(predictions, dim = -1)\n",
    "\n",
    "    # Get top-k words\n",
    "    top_k_probs, top_k_indices = torch.topk(log_probs, beam_width, dim=-1)\n",
    "    top_k_probs = top_k_probs.squeeze().tolist()\n",
    "    top_k_indices = top_k_indices.squeeze().tolist()\n",
    "\n",
    "    next_words = [(word, prob) for word, prob in zip(top_k_indices, top_k_probs)]\n",
    "    return next_words\n",
    "\n",
    "\n",
    "def beam_search(transformer, question, question_mask, max_len, dict, beam_width=5):\n",
    "    transformer.eval()\n",
    "    start_token = 1\n",
    "    end_token = 2\n",
    "\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "\n",
    "    beams = [([], 0)] \n",
    "\n",
    "    for step in range(max_len):\n",
    "        candidates = []\n",
    "\n",
    "        for seq, score in beams:\n",
    "            if seq and seq[-1] == end_token:\n",
    "                candidates.append((seq, score))\n",
    "                continue\n",
    "            \n",
    "            next_words = generate_next_words(transformer, seq, encoded, question_mask, beam_width)\n",
    "\n",
    "            for word, log_prob in next_words:\n",
    "                candidates.append((seq + [word], score + log_prob))\n",
    "\n",
    "        # Select top-k candidates\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        beams = candidates[:beam_width]\n",
    "\n",
    "        # Check if all beams have ended\n",
    "        if all(seq[-1] == end_token for seq, _ in beams):\n",
    "            break\n",
    "\n",
    "    best_seq, _ = max(beams, key=lambda x: x[1])\n",
    "    return best_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bb = {v:k for k,v in ww_dict.items()} \n",
    "\n",
    "bb[0] = '<pad>'\n",
    "bb[1] = '<start>'\n",
    "bb[2] = '<end>'\n",
    "bb[3] = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, transformer, criterion, epoch):\n",
    "    \n",
    "    transformer.train()\n",
    "    sum_loss, valid_sum_loss = 0, 0\n",
    "    count, valid_count = 0, 0\n",
    "    \n",
    "    for i, (inputs, output) in enumerate(train_loader):\n",
    "        \n",
    "        samples = inputs.shape[0]\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        output = output.to(device)\n",
    "        \n",
    "        output_in = output[:,:-1]\n",
    "        output_target = output[:,1:]\n",
    "        inputs_mask, output_in_mask, output_target_mask = create_masks(inputs, output_in, output_target)\n",
    "        \n",
    "        out = transformer(inputs, inputs_mask, output_in, output_in_mask)\n",
    "        \n",
    "        loss = criterion(out, output_target, output_target_mask)\n",
    "        transformer_optimizer.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        transformer_optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item() * samples\n",
    "        count += samples\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(\"Epoch [{}][{}/{}]\\tTrain Loss: {:.3f}\".format(epoch, i, len(train_loader), sum_loss/count))\n",
    "            wandb.log({\"Training loss\" : sum_loss/count})\n",
    "    \n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, output) in enumerate(valid_loader):\n",
    "            \n",
    "            samples = inputs.shape[0]\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            output = output.to(device)\n",
    "            \n",
    "            output_in = output[:,:-1]\n",
    "            output_target = output[:,1:]\n",
    "            \n",
    "            inputs_mask, output_in_mask, output_target_mask = create_masks(inputs, output_in, output_target)\n",
    "            out = transformer(inputs, inputs_mask, output_in, output_in_mask)\n",
    "            \n",
    "            loss = criterion(out, output_target, output_target_mask)\n",
    "            \n",
    "            valid_sum_loss += loss.item() * samples\n",
    "            valid_count += samples\n",
    "        \n",
    "            if i % 5   == 0:\n",
    "                print(\"Epoch [{}][{}/{}]\\t\\t\\tValid Loss: {:.3f}\".format(epoch, i, len(valid_loader), valid_sum_loss/valid_count))\n",
    "                wandb.log({\"Validation loss\" :  valid_sum_loss/valid_count })\n",
    "                \n",
    "\n",
    "    max_len = 128\n",
    "    A = random.randint(1, 64)\n",
    "    B = next(iter(test_loader))\n",
    "    \n",
    "    enc_qus = B[0][A]\n",
    "    real_qus = B[1][A]\n",
    "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "    question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)\n",
    "    sentence = beam_search(transformer, question, question_mask, int(max_len), dict)\n",
    "    \n",
    "    candidate = [bb[i] for i in sentence if (i != 2) and (i != 0) and (i != 1)]\n",
    "    real = [bb[i.tolist()] for i in real_qus if (i.tolist() != 2) and (i.tolist() != 0)  and (i != 1)]\n",
    "    print()\n",
    "    print('Candidate_labeled : ', [bb[i] for i in sentence])\n",
    "    print('Candidate :'  + ' '.join(candidate))\n",
    "    print('Real :' + ' '.join(real))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 724.0773, 1448.1547, 1448.1547])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor((64, 128, 128)) * math.sqrt(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_en_final, train_ge_final)\n",
    "valid_dataset = Dataset(valid_en_final, valid_ge_final)\n",
    "test_dataset = Dataset(test_en_final, test_ge_final)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True, drop_last = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 64, shuffle = True, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28998"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_en_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random.randint(1, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][0/453]\tTrain Loss: 2.042\n",
      "Epoch [0][5/453]\tTrain Loss: 1.991\n",
      "Epoch [0][10/453]\tTrain Loss: 1.962\n",
      "Epoch [0][15/453]\tTrain Loss: 1.939\n",
      "Epoch [0][20/453]\tTrain Loss: 1.931\n",
      "Epoch [0][25/453]\tTrain Loss: 1.950\n",
      "Epoch [0][30/453]\tTrain Loss: 1.944\n",
      "Epoch [0][35/453]\tTrain Loss: 1.929\n",
      "Epoch [0][40/453]\tTrain Loss: 1.925\n",
      "Epoch [0][45/453]\tTrain Loss: 1.931\n",
      "Epoch [0][50/453]\tTrain Loss: 1.924\n",
      "Epoch [0][55/453]\tTrain Loss: 1.930\n",
      "Epoch [0][60/453]\tTrain Loss: 1.933\n",
      "Epoch [0][65/453]\tTrain Loss: 1.935\n",
      "Epoch [0][70/453]\tTrain Loss: 1.939\n",
      "Epoch [0][75/453]\tTrain Loss: 1.936\n",
      "Epoch [0][80/453]\tTrain Loss: 1.937\n",
      "Epoch [0][85/453]\tTrain Loss: 1.941\n",
      "Epoch [0][90/453]\tTrain Loss: 1.943\n",
      "Epoch [0][95/453]\tTrain Loss: 1.948\n",
      "Epoch [0][100/453]\tTrain Loss: 1.949\n",
      "Epoch [0][105/453]\tTrain Loss: 1.950\n",
      "Epoch [0][110/453]\tTrain Loss: 1.954\n",
      "Epoch [0][115/453]\tTrain Loss: 1.961\n",
      "Epoch [0][120/453]\tTrain Loss: 1.963\n",
      "Epoch [0][125/453]\tTrain Loss: 1.966\n",
      "Epoch [0][130/453]\tTrain Loss: 1.965\n",
      "Epoch [0][135/453]\tTrain Loss: 1.967\n",
      "Epoch [0][140/453]\tTrain Loss: 1.968\n",
      "Epoch [0][145/453]\tTrain Loss: 1.966\n",
      "Epoch [0][150/453]\tTrain Loss: 1.967\n",
      "Epoch [0][155/453]\tTrain Loss: 1.968\n",
      "Epoch [0][160/453]\tTrain Loss: 1.969\n",
      "Epoch [0][165/453]\tTrain Loss: 1.970\n",
      "Epoch [0][170/453]\tTrain Loss: 1.971\n",
      "Epoch [0][175/453]\tTrain Loss: 1.972\n",
      "Epoch [0][180/453]\tTrain Loss: 1.973\n",
      "Epoch [0][185/453]\tTrain Loss: 1.976\n",
      "Epoch [0][190/453]\tTrain Loss: 1.976\n",
      "Epoch [0][195/453]\tTrain Loss: 1.978\n",
      "Epoch [0][200/453]\tTrain Loss: 1.981\n",
      "Epoch [0][205/453]\tTrain Loss: 1.983\n",
      "Epoch [0][210/453]\tTrain Loss: 1.982\n",
      "Epoch [0][215/453]\tTrain Loss: 1.982\n",
      "Epoch [0][220/453]\tTrain Loss: 1.984\n",
      "Epoch [0][225/453]\tTrain Loss: 1.985\n",
      "Epoch [0][230/453]\tTrain Loss: 1.989\n",
      "Epoch [0][235/453]\tTrain Loss: 1.988\n",
      "Epoch [0][240/453]\tTrain Loss: 1.989\n",
      "Epoch [0][245/453]\tTrain Loss: 1.992\n",
      "Epoch [0][250/453]\tTrain Loss: 1.993\n",
      "Epoch [0][255/453]\tTrain Loss: 1.995\n",
      "Epoch [0][260/453]\tTrain Loss: 1.997\n",
      "Epoch [0][265/453]\tTrain Loss: 1.999\n",
      "Epoch [0][270/453]\tTrain Loss: 1.999\n",
      "Epoch [0][275/453]\tTrain Loss: 1.999\n",
      "Epoch [0][280/453]\tTrain Loss: 2.000\n",
      "Epoch [0][285/453]\tTrain Loss: 2.002\n",
      "Epoch [0][290/453]\tTrain Loss: 2.002\n",
      "Epoch [0][295/453]\tTrain Loss: 2.003\n",
      "Epoch [0][300/453]\tTrain Loss: 2.004\n",
      "Epoch [0][305/453]\tTrain Loss: 2.004\n",
      "Epoch [0][310/453]\tTrain Loss: 2.006\n",
      "Epoch [0][315/453]\tTrain Loss: 2.006\n",
      "Epoch [0][320/453]\tTrain Loss: 2.006\n",
      "Epoch [0][325/453]\tTrain Loss: 2.007\n",
      "Epoch [0][330/453]\tTrain Loss: 2.009\n",
      "Epoch [0][335/453]\tTrain Loss: 2.010\n",
      "Epoch [0][340/453]\tTrain Loss: 2.013\n",
      "Epoch [0][345/453]\tTrain Loss: 2.014\n",
      "Epoch [0][350/453]\tTrain Loss: 2.015\n",
      "Epoch [0][355/453]\tTrain Loss: 2.016\n",
      "Epoch [0][360/453]\tTrain Loss: 2.016\n",
      "Epoch [0][365/453]\tTrain Loss: 2.018\n",
      "Epoch [0][370/453]\tTrain Loss: 2.019\n",
      "Epoch [0][375/453]\tTrain Loss: 2.019\n",
      "Epoch [0][380/453]\tTrain Loss: 2.020\n",
      "Epoch [0][385/453]\tTrain Loss: 2.021\n",
      "Epoch [0][390/453]\tTrain Loss: 2.020\n",
      "Epoch [0][395/453]\tTrain Loss: 2.020\n",
      "Epoch [0][400/453]\tTrain Loss: 2.021\n",
      "Epoch [0][405/453]\tTrain Loss: 2.022\n",
      "Epoch [0][410/453]\tTrain Loss: 2.021\n",
      "Epoch [0][415/453]\tTrain Loss: 2.021\n",
      "Epoch [0][420/453]\tTrain Loss: 2.022\n",
      "Epoch [0][425/453]\tTrain Loss: 2.022\n",
      "Epoch [0][430/453]\tTrain Loss: 2.022\n",
      "Epoch [0][435/453]\tTrain Loss: 2.023\n",
      "Epoch [0][440/453]\tTrain Loss: 2.023\n",
      "Epoch [0][445/453]\tTrain Loss: 2.023\n",
      "Epoch [0][450/453]\tTrain Loss: 2.023\n",
      "Epoch [0][0/15]\t\t\tValid Loss: 3.027\n",
      "Epoch [0][5/15]\t\t\tValid Loss: 2.864\n",
      "Epoch [0][10/15]\t\t\tValid Loss: 2.815\n",
      "\n",
      "Candidate_labeled :  ['<start>', 'Ein', 'Mann', 'steht', 'einer', 'Bar', 'mit', 'Werkzeugen', '.', '<end>']\n",
      "Candidate :Ein Mann steht einer Bar mit Werkzeugen .\n",
      "Real :Ein Mann steht bei einigen Spielautomaten einer Bar .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:02:08.652259 #######\n",
      "\n",
      "Epoch [1][0/453]\tTrain Loss: 1.849\n",
      "Epoch [1][5/453]\tTrain Loss: 1.768\n",
      "Epoch [1][10/453]\tTrain Loss: 1.795\n",
      "Epoch [1][15/453]\tTrain Loss: 1.778\n",
      "Epoch [1][20/453]\tTrain Loss: 1.788\n",
      "Epoch [1][25/453]\tTrain Loss: 1.778\n",
      "Epoch [1][30/453]\tTrain Loss: 1.786\n",
      "Epoch [1][35/453]\tTrain Loss: 1.787\n",
      "Epoch [1][40/453]\tTrain Loss: 1.787\n",
      "Epoch [1][45/453]\tTrain Loss: 1.777\n",
      "Epoch [1][50/453]\tTrain Loss: 1.783\n",
      "Epoch [1][55/453]\tTrain Loss: 1.786\n",
      "Epoch [1][60/453]\tTrain Loss: 1.788\n",
      "Epoch [1][65/453]\tTrain Loss: 1.788\n",
      "Epoch [1][70/453]\tTrain Loss: 1.787\n",
      "Epoch [1][75/453]\tTrain Loss: 1.798\n",
      "Epoch [1][80/453]\tTrain Loss: 1.796\n",
      "Epoch [1][85/453]\tTrain Loss: 1.803\n",
      "Epoch [1][90/453]\tTrain Loss: 1.805\n",
      "Epoch [1][95/453]\tTrain Loss: 1.806\n",
      "Epoch [1][100/453]\tTrain Loss: 1.805\n",
      "Epoch [1][105/453]\tTrain Loss: 1.810\n",
      "Epoch [1][110/453]\tTrain Loss: 1.811\n",
      "Epoch [1][115/453]\tTrain Loss: 1.812\n",
      "Epoch [1][120/453]\tTrain Loss: 1.813\n",
      "Epoch [1][125/453]\tTrain Loss: 1.815\n",
      "Epoch [1][130/453]\tTrain Loss: 1.814\n",
      "Epoch [1][135/453]\tTrain Loss: 1.815\n",
      "Epoch [1][140/453]\tTrain Loss: 1.817\n",
      "Epoch [1][145/453]\tTrain Loss: 1.819\n",
      "Epoch [1][150/453]\tTrain Loss: 1.822\n",
      "Epoch [1][155/453]\tTrain Loss: 1.823\n",
      "Epoch [1][160/453]\tTrain Loss: 1.825\n",
      "Epoch [1][165/453]\tTrain Loss: 1.828\n",
      "Epoch [1][170/453]\tTrain Loss: 1.827\n",
      "Epoch [1][175/453]\tTrain Loss: 1.829\n",
      "Epoch [1][180/453]\tTrain Loss: 1.831\n",
      "Epoch [1][185/453]\tTrain Loss: 1.833\n",
      "Epoch [1][190/453]\tTrain Loss: 1.833\n",
      "Epoch [1][195/453]\tTrain Loss: 1.833\n",
      "Epoch [1][200/453]\tTrain Loss: 1.835\n",
      "Epoch [1][205/453]\tTrain Loss: 1.837\n",
      "Epoch [1][210/453]\tTrain Loss: 1.840\n",
      "Epoch [1][215/453]\tTrain Loss: 1.841\n",
      "Epoch [1][220/453]\tTrain Loss: 1.842\n",
      "Epoch [1][225/453]\tTrain Loss: 1.843\n",
      "Epoch [1][230/453]\tTrain Loss: 1.845\n",
      "Epoch [1][235/453]\tTrain Loss: 1.845\n",
      "Epoch [1][240/453]\tTrain Loss: 1.845\n",
      "Epoch [1][245/453]\tTrain Loss: 1.845\n",
      "Epoch [1][250/453]\tTrain Loss: 1.847\n",
      "Epoch [1][255/453]\tTrain Loss: 1.847\n",
      "Epoch [1][260/453]\tTrain Loss: 1.848\n",
      "Epoch [1][265/453]\tTrain Loss: 1.849\n",
      "Epoch [1][270/453]\tTrain Loss: 1.849\n",
      "Epoch [1][275/453]\tTrain Loss: 1.852\n",
      "Epoch [1][280/453]\tTrain Loss: 1.853\n",
      "Epoch [1][285/453]\tTrain Loss: 1.854\n",
      "Epoch [1][290/453]\tTrain Loss: 1.856\n",
      "Epoch [1][295/453]\tTrain Loss: 1.857\n",
      "Epoch [1][300/453]\tTrain Loss: 1.858\n",
      "Epoch [1][305/453]\tTrain Loss: 1.858\n",
      "Epoch [1][310/453]\tTrain Loss: 1.859\n",
      "Epoch [1][315/453]\tTrain Loss: 1.860\n",
      "Epoch [1][320/453]\tTrain Loss: 1.862\n",
      "Epoch [1][325/453]\tTrain Loss: 1.864\n",
      "Epoch [1][330/453]\tTrain Loss: 1.865\n",
      "Epoch [1][335/453]\tTrain Loss: 1.864\n",
      "Epoch [1][340/453]\tTrain Loss: 1.864\n",
      "Epoch [1][345/453]\tTrain Loss: 1.866\n",
      "Epoch [1][350/453]\tTrain Loss: 1.867\n",
      "Epoch [1][355/453]\tTrain Loss: 1.867\n",
      "Epoch [1][360/453]\tTrain Loss: 1.868\n",
      "Epoch [1][365/453]\tTrain Loss: 1.869\n",
      "Epoch [1][370/453]\tTrain Loss: 1.870\n",
      "Epoch [1][375/453]\tTrain Loss: 1.871\n",
      "Epoch [1][380/453]\tTrain Loss: 1.872\n",
      "Epoch [1][385/453]\tTrain Loss: 1.873\n",
      "Epoch [1][390/453]\tTrain Loss: 1.874\n",
      "Epoch [1][395/453]\tTrain Loss: 1.875\n",
      "Epoch [1][400/453]\tTrain Loss: 1.875\n",
      "Epoch [1][405/453]\tTrain Loss: 1.876\n",
      "Epoch [1][410/453]\tTrain Loss: 1.877\n",
      "Epoch [1][415/453]\tTrain Loss: 1.877\n",
      "Epoch [1][420/453]\tTrain Loss: 1.877\n",
      "Epoch [1][425/453]\tTrain Loss: 1.878\n",
      "Epoch [1][430/453]\tTrain Loss: 1.877\n",
      "Epoch [1][435/453]\tTrain Loss: 1.878\n",
      "Epoch [1][440/453]\tTrain Loss: 1.879\n",
      "Epoch [1][445/453]\tTrain Loss: 1.880\n",
      "Epoch [1][450/453]\tTrain Loss: 1.881\n",
      "Epoch [1][0/15]\t\t\tValid Loss: 2.983\n",
      "Epoch [1][5/15]\t\t\tValid Loss: 2.801\n",
      "Epoch [1][10/15]\t\t\tValid Loss: 2.743\n",
      "\n",
      "Candidate_labeled :  ['<start>', 'Die', 'junge', 'Dame', 'schaut', 'hinaus', '.', '<end>']\n",
      "Candidate :Die junge Dame schaut hinaus .\n",
      "Real :Die junge Dame sieht auf die Pizza .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:02:03.191944 #######\n",
      "\n",
      "Epoch [2][0/453]\tTrain Loss: 1.555\n",
      "Epoch [2][5/453]\tTrain Loss: 1.577\n",
      "Epoch [2][10/453]\tTrain Loss: 1.588\n",
      "Epoch [2][15/453]\tTrain Loss: 1.610\n",
      "Epoch [2][20/453]\tTrain Loss: 1.620\n",
      "Epoch [2][25/453]\tTrain Loss: 1.634\n",
      "Epoch [2][30/453]\tTrain Loss: 1.643\n",
      "Epoch [2][35/453]\tTrain Loss: 1.648\n",
      "Epoch [2][40/453]\tTrain Loss: 1.659\n",
      "Epoch [2][45/453]\tTrain Loss: 1.665\n",
      "Epoch [2][50/453]\tTrain Loss: 1.665\n",
      "Epoch [2][55/453]\tTrain Loss: 1.671\n",
      "Epoch [2][60/453]\tTrain Loss: 1.671\n",
      "Epoch [2][65/453]\tTrain Loss: 1.673\n",
      "Epoch [2][70/453]\tTrain Loss: 1.677\n",
      "Epoch [2][75/453]\tTrain Loss: 1.682\n",
      "Epoch [2][80/453]\tTrain Loss: 1.690\n",
      "Epoch [2][85/453]\tTrain Loss: 1.690\n",
      "Epoch [2][90/453]\tTrain Loss: 1.693\n",
      "Epoch [2][95/453]\tTrain Loss: 1.692\n",
      "Epoch [2][100/453]\tTrain Loss: 1.690\n",
      "Epoch [2][105/453]\tTrain Loss: 1.694\n",
      "Epoch [2][110/453]\tTrain Loss: 1.696\n",
      "Epoch [2][115/453]\tTrain Loss: 1.695\n",
      "Epoch [2][120/453]\tTrain Loss: 1.695\n",
      "Epoch [2][125/453]\tTrain Loss: 1.696\n",
      "Epoch [2][130/453]\tTrain Loss: 1.696\n",
      "Epoch [2][135/453]\tTrain Loss: 1.698\n",
      "Epoch [2][140/453]\tTrain Loss: 1.701\n",
      "Epoch [2][145/453]\tTrain Loss: 1.702\n",
      "Epoch [2][150/453]\tTrain Loss: 1.705\n",
      "Epoch [2][155/453]\tTrain Loss: 1.705\n",
      "Epoch [2][160/453]\tTrain Loss: 1.705\n",
      "Epoch [2][165/453]\tTrain Loss: 1.703\n",
      "Epoch [2][170/453]\tTrain Loss: 1.705\n",
      "Epoch [2][175/453]\tTrain Loss: 1.707\n",
      "Epoch [2][180/453]\tTrain Loss: 1.709\n",
      "Epoch [2][185/453]\tTrain Loss: 1.713\n",
      "Epoch [2][190/453]\tTrain Loss: 1.712\n",
      "Epoch [2][195/453]\tTrain Loss: 1.713\n",
      "Epoch [2][200/453]\tTrain Loss: 1.713\n",
      "Epoch [2][205/453]\tTrain Loss: 1.712\n",
      "Epoch [2][210/453]\tTrain Loss: 1.714\n",
      "Epoch [2][215/453]\tTrain Loss: 1.716\n",
      "Epoch [2][220/453]\tTrain Loss: 1.718\n",
      "Epoch [2][225/453]\tTrain Loss: 1.720\n",
      "Epoch [2][230/453]\tTrain Loss: 1.722\n",
      "Epoch [2][235/453]\tTrain Loss: 1.723\n",
      "Epoch [2][240/453]\tTrain Loss: 1.725\n",
      "Epoch [2][245/453]\tTrain Loss: 1.726\n",
      "Epoch [2][250/453]\tTrain Loss: 1.726\n",
      "Epoch [2][255/453]\tTrain Loss: 1.729\n",
      "Epoch [2][260/453]\tTrain Loss: 1.730\n",
      "Epoch [2][265/453]\tTrain Loss: 1.730\n",
      "Epoch [2][270/453]\tTrain Loss: 1.731\n",
      "Epoch [2][275/453]\tTrain Loss: 1.731\n",
      "Epoch [2][280/453]\tTrain Loss: 1.733\n",
      "Epoch [2][285/453]\tTrain Loss: 1.732\n",
      "Epoch [2][290/453]\tTrain Loss: 1.733\n",
      "Epoch [2][295/453]\tTrain Loss: 1.735\n",
      "Epoch [2][300/453]\tTrain Loss: 1.736\n",
      "Epoch [2][305/453]\tTrain Loss: 1.736\n",
      "Epoch [2][310/453]\tTrain Loss: 1.738\n",
      "Epoch [2][315/453]\tTrain Loss: 1.740\n",
      "Epoch [2][320/453]\tTrain Loss: 1.740\n",
      "Epoch [2][325/453]\tTrain Loss: 1.740\n",
      "Epoch [2][330/453]\tTrain Loss: 1.743\n",
      "Epoch [2][335/453]\tTrain Loss: 1.744\n",
      "Epoch [2][340/453]\tTrain Loss: 1.744\n",
      "Epoch [2][345/453]\tTrain Loss: 1.745\n",
      "Epoch [2][350/453]\tTrain Loss: 1.745\n",
      "Epoch [2][355/453]\tTrain Loss: 1.748\n",
      "Epoch [2][360/453]\tTrain Loss: 1.748\n",
      "Epoch [2][365/453]\tTrain Loss: 1.749\n",
      "Epoch [2][370/453]\tTrain Loss: 1.749\n",
      "Epoch [2][375/453]\tTrain Loss: 1.750\n",
      "Epoch [2][380/453]\tTrain Loss: 1.750\n",
      "Epoch [2][385/453]\tTrain Loss: 1.752\n",
      "Epoch [2][390/453]\tTrain Loss: 1.753\n",
      "Epoch [2][395/453]\tTrain Loss: 1.754\n",
      "Epoch [2][400/453]\tTrain Loss: 1.753\n",
      "Epoch [2][405/453]\tTrain Loss: 1.754\n",
      "Epoch [2][410/453]\tTrain Loss: 1.754\n",
      "Epoch [2][415/453]\tTrain Loss: 1.754\n",
      "Epoch [2][420/453]\tTrain Loss: 1.754\n",
      "Epoch [2][425/453]\tTrain Loss: 1.755\n",
      "Epoch [2][430/453]\tTrain Loss: 1.756\n",
      "Epoch [2][435/453]\tTrain Loss: 1.756\n",
      "Epoch [2][440/453]\tTrain Loss: 1.757\n",
      "Epoch [2][445/453]\tTrain Loss: 1.758\n",
      "Epoch [2][450/453]\tTrain Loss: 1.757\n",
      "Epoch [2][0/15]\t\t\tValid Loss: 2.888\n",
      "Epoch [2][5/15]\t\t\tValid Loss: 2.812\n",
      "Epoch [2][10/15]\t\t\tValid Loss: 2.844\n",
      "\n",
      "Candidate_labeled :  ['<start>', 'Eine', 'Frau', 'einem', 'rosa', 'Pullover', 'und', 'Schürze', 'reinigt', 'einen', 'Tisch', '.', '<end>']\n",
      "Candidate :Eine Frau einem rosa Pullover und Schürze reinigt einen Tisch .\n",
      "Real :Eine Frau einem pinken Pulli und einer Schürze putzt einen Tisch mit einem Schwamm .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:02:53.323299 #######\n",
      "\n",
      "Epoch [3][0/453]\tTrain Loss: 1.486\n",
      "Epoch [3][5/453]\tTrain Loss: 1.489\n",
      "Epoch [3][10/453]\tTrain Loss: 1.572\n",
      "Epoch [3][15/453]\tTrain Loss: 1.575\n",
      "Epoch [3][20/453]\tTrain Loss: 1.578\n",
      "Epoch [3][25/453]\tTrain Loss: 1.587\n",
      "Epoch [3][30/453]\tTrain Loss: 1.589\n",
      "Epoch [3][35/453]\tTrain Loss: 1.583\n",
      "Epoch [3][40/453]\tTrain Loss: 1.580\n",
      "Epoch [3][45/453]\tTrain Loss: 1.578\n",
      "Epoch [3][50/453]\tTrain Loss: 1.576\n",
      "Epoch [3][55/453]\tTrain Loss: 1.577\n",
      "Epoch [3][60/453]\tTrain Loss: 1.573\n",
      "Epoch [3][65/453]\tTrain Loss: 1.577\n",
      "Epoch [3][70/453]\tTrain Loss: 1.577\n",
      "Epoch [3][75/453]\tTrain Loss: 1.573\n",
      "Epoch [3][80/453]\tTrain Loss: 1.575\n",
      "Epoch [3][85/453]\tTrain Loss: 1.573\n",
      "Epoch [3][90/453]\tTrain Loss: 1.572\n",
      "Epoch [3][95/453]\tTrain Loss: 1.575\n",
      "Epoch [3][100/453]\tTrain Loss: 1.575\n",
      "Epoch [3][105/453]\tTrain Loss: 1.579\n",
      "Epoch [3][110/453]\tTrain Loss: 1.583\n",
      "Epoch [3][115/453]\tTrain Loss: 1.586\n",
      "Epoch [3][120/453]\tTrain Loss: 1.591\n",
      "Epoch [3][125/453]\tTrain Loss: 1.592\n",
      "Epoch [3][130/453]\tTrain Loss: 1.593\n",
      "Epoch [3][135/453]\tTrain Loss: 1.594\n",
      "Epoch [3][140/453]\tTrain Loss: 1.595\n",
      "Epoch [3][145/453]\tTrain Loss: 1.596\n",
      "Epoch [3][150/453]\tTrain Loss: 1.599\n",
      "Epoch [3][155/453]\tTrain Loss: 1.600\n",
      "Epoch [3][160/453]\tTrain Loss: 1.600\n",
      "Epoch [3][165/453]\tTrain Loss: 1.599\n",
      "Epoch [3][170/453]\tTrain Loss: 1.600\n",
      "Epoch [3][175/453]\tTrain Loss: 1.603\n",
      "Epoch [3][180/453]\tTrain Loss: 1.603\n",
      "Epoch [3][185/453]\tTrain Loss: 1.605\n",
      "Epoch [3][190/453]\tTrain Loss: 1.606\n",
      "Epoch [3][195/453]\tTrain Loss: 1.609\n",
      "Epoch [3][200/453]\tTrain Loss: 1.610\n",
      "Epoch [3][205/453]\tTrain Loss: 1.612\n",
      "Epoch [3][210/453]\tTrain Loss: 1.611\n",
      "Epoch [3][215/453]\tTrain Loss: 1.614\n",
      "Epoch [3][220/453]\tTrain Loss: 1.615\n",
      "Epoch [3][225/453]\tTrain Loss: 1.616\n",
      "Epoch [3][230/453]\tTrain Loss: 1.619\n",
      "Epoch [3][235/453]\tTrain Loss: 1.618\n",
      "Epoch [3][240/453]\tTrain Loss: 1.618\n",
      "Epoch [3][245/453]\tTrain Loss: 1.620\n",
      "Epoch [3][250/453]\tTrain Loss: 1.622\n",
      "Epoch [3][255/453]\tTrain Loss: 1.622\n",
      "Epoch [3][260/453]\tTrain Loss: 1.623\n",
      "Epoch [3][265/453]\tTrain Loss: 1.623\n",
      "Epoch [3][270/453]\tTrain Loss: 1.624\n",
      "Epoch [3][275/453]\tTrain Loss: 1.624\n",
      "Epoch [3][280/453]\tTrain Loss: 1.627\n",
      "Epoch [3][285/453]\tTrain Loss: 1.628\n",
      "Epoch [3][290/453]\tTrain Loss: 1.628\n",
      "Epoch [3][295/453]\tTrain Loss: 1.629\n",
      "Epoch [3][300/453]\tTrain Loss: 1.629\n",
      "Epoch [3][305/453]\tTrain Loss: 1.631\n",
      "Epoch [3][310/453]\tTrain Loss: 1.632\n",
      "Epoch [3][315/453]\tTrain Loss: 1.633\n",
      "Epoch [3][320/453]\tTrain Loss: 1.633\n",
      "Epoch [3][325/453]\tTrain Loss: 1.634\n",
      "Epoch [3][330/453]\tTrain Loss: 1.636\n",
      "Epoch [3][335/453]\tTrain Loss: 1.636\n",
      "Epoch [3][340/453]\tTrain Loss: 1.636\n",
      "Epoch [3][345/453]\tTrain Loss: 1.636\n",
      "Epoch [3][350/453]\tTrain Loss: 1.637\n",
      "Epoch [3][355/453]\tTrain Loss: 1.639\n",
      "Epoch [3][360/453]\tTrain Loss: 1.639\n",
      "Epoch [3][365/453]\tTrain Loss: 1.640\n",
      "Epoch [3][370/453]\tTrain Loss: 1.640\n",
      "Epoch [3][375/453]\tTrain Loss: 1.642\n",
      "Epoch [3][380/453]\tTrain Loss: 1.644\n",
      "Epoch [3][385/453]\tTrain Loss: 1.643\n",
      "Epoch [3][390/453]\tTrain Loss: 1.644\n",
      "Epoch [3][395/453]\tTrain Loss: 1.645\n",
      "Epoch [3][400/453]\tTrain Loss: 1.645\n",
      "Epoch [3][405/453]\tTrain Loss: 1.646\n",
      "Epoch [3][410/453]\tTrain Loss: 1.647\n",
      "Epoch [3][415/453]\tTrain Loss: 1.647\n",
      "Epoch [3][420/453]\tTrain Loss: 1.649\n",
      "Epoch [3][425/453]\tTrain Loss: 1.650\n",
      "Epoch [3][430/453]\tTrain Loss: 1.651\n",
      "Epoch [3][435/453]\tTrain Loss: 1.651\n",
      "Epoch [3][440/453]\tTrain Loss: 1.652\n",
      "Epoch [3][445/453]\tTrain Loss: 1.653\n",
      "Epoch [3][450/453]\tTrain Loss: 1.653\n",
      "Epoch [3][0/15]\t\t\tValid Loss: 3.040\n",
      "Epoch [3][5/15]\t\t\tValid Loss: 2.784\n",
      "Epoch [3][10/15]\t\t\tValid Loss: 2.815\n",
      "\n",
      "Candidate_labeled :  ['<start>', 'Ein', 'Mann', 'kocht', 'Essen', 'auf', 'einem', 'Herd', '.', '<end>']\n",
      "Candidate :Ein Mann kocht Essen auf einem Herd .\n",
      "Real :Ein Mann bereitet Herd Essen zu .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:02:01.202977 #######\n",
      "\n",
      "Epoch [4][0/453]\tTrain Loss: 1.349\n",
      "Epoch [4][5/453]\tTrain Loss: 1.432\n",
      "Epoch [4][10/453]\tTrain Loss: 1.448\n",
      "Epoch [4][15/453]\tTrain Loss: 1.445\n",
      "Epoch [4][20/453]\tTrain Loss: 1.453\n",
      "Epoch [4][25/453]\tTrain Loss: 1.467\n",
      "Epoch [4][30/453]\tTrain Loss: 1.471\n",
      "Epoch [4][35/453]\tTrain Loss: 1.468\n",
      "Epoch [4][40/453]\tTrain Loss: 1.470\n",
      "Epoch [4][45/453]\tTrain Loss: 1.467\n",
      "Epoch [4][50/453]\tTrain Loss: 1.467\n",
      "Epoch [4][55/453]\tTrain Loss: 1.473\n",
      "Epoch [4][60/453]\tTrain Loss: 1.473\n",
      "Epoch [4][65/453]\tTrain Loss: 1.474\n",
      "Epoch [4][70/453]\tTrain Loss: 1.481\n",
      "Epoch [4][75/453]\tTrain Loss: 1.481\n",
      "Epoch [4][80/453]\tTrain Loss: 1.484\n",
      "Epoch [4][85/453]\tTrain Loss: 1.484\n",
      "Epoch [4][90/453]\tTrain Loss: 1.489\n",
      "Epoch [4][95/453]\tTrain Loss: 1.491\n",
      "Epoch [4][100/453]\tTrain Loss: 1.492\n",
      "Epoch [4][105/453]\tTrain Loss: 1.495\n",
      "Epoch [4][110/453]\tTrain Loss: 1.497\n",
      "Epoch [4][115/453]\tTrain Loss: 1.499\n",
      "Epoch [4][120/453]\tTrain Loss: 1.499\n",
      "Epoch [4][125/453]\tTrain Loss: 1.502\n",
      "Epoch [4][130/453]\tTrain Loss: 1.503\n",
      "Epoch [4][135/453]\tTrain Loss: 1.504\n",
      "Epoch [4][140/453]\tTrain Loss: 1.504\n",
      "Epoch [4][145/453]\tTrain Loss: 1.503\n",
      "Epoch [4][150/453]\tTrain Loss: 1.502\n",
      "Epoch [4][155/453]\tTrain Loss: 1.504\n",
      "Epoch [4][160/453]\tTrain Loss: 1.504\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      7\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \n\u001b[1;32m----> 8\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer_optimizer}\n\u001b[0;32m     11\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_p_transformer_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[47], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, transformer, criterion, epoch)\u001b[0m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, output_target, output_target_mask)\n\u001b[0;32m     21\u001b[0m transformer_optimizer\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m transformer_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     25\u001b[0m sum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m samples\n",
      "File \u001b[1;32md:\\anaconda\\envs\\Pray\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\Pray\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start_time = datetime.now() \n",
    "    train(train_loader, transformer, criterion, epoch)\n",
    "    \n",
    "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    torch.save(state, 'checkpoint_p_transformer_' + str(epoch + 10) + '.pth.tar')\n",
    "    \n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print('#######   Time elapsed (hh:mm:ss.ms) {} #######'.format(time_elapsed))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_Transformer(\n",
       "  (embed): Embeddings(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (embed): Embedding(28778, 64)\n",
       "  )\n",
       "  (encoder): ModuleList(\n",
       "    (0-5): 6 x EncoderLayer(\n",
       "      (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_multihead): MultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (concat): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (fc1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0-5): 6 x DecoderLayer(\n",
       "      (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_multihead): MultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (concat): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (src_multihead): MultiHeadAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (concat): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (fc1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (logit): Linear(in_features=64, out_features=28778, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "# 저장된 파일을 불러올 때\n",
    "checkpoint = torch.load('checkpoint_p_transformer_11.pth.tar')\n",
    "\n",
    "# 불러온 checkpoint에서 모델 상태나 다른 필요한 요소들을 추출할 수 있습니다.\n",
    "transformer = deepcopy(checkpoint['transformer'])\n",
    "\n",
    "# 모델을 evaluation 모드로 설정 (필요에 따라)\n",
    "transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/999 [00:12<19:32,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3337512154858845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/999 [00:21<14:41,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18920783558232607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/999 [00:30<15:03,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.17007941171469537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 40/999 [00:39<13:39,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19086096780031797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/999 [00:48<13:16,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.21042885098148165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 60/999 [00:56<14:58,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19104696783077924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 70/999 [01:06<12:33,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18824528865915127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 80/999 [01:15<15:28,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18281986397697997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 90/999 [01:25<14:37,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.17702178314578157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/999 [01:34<14:15,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.16888549970580194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 110/999 [01:44<14:34,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.167569589541419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 120/999 [01:54<12:57,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.16327152288531988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 130/999 [02:03<12:53,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.16206123062094305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 140/999 [02:12<11:46,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.15797673663050188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 150/999 [02:22<12:55,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.15749448771875266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 160/999 [02:32<16:17,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.16471828502367442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 170/999 [02:41<11:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.16896959299839862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 180/999 [02:50<11:53,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.16997810534325963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 190/999 [02:59<11:45,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.16864649662134856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/999 [03:09<14:08,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.16787913018324394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 210/999 [03:15<08:06,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1721534094116526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 220/999 [03:24<12:12,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1690135165681405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 230/999 [03:35<16:06,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.17159776996347806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 240/999 [03:45<11:41,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.17371255353624127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 250/999 [03:55<11:01,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.17360111227176633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 260/999 [04:05<10:31,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1732672751108763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 270/999 [04:16<13:45,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.17446755112783074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 280/999 [04:24<10:13,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.17908189730797536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 290/999 [04:32<09:40,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18421788894888702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/999 [04:40<08:43,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.187268298053129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 310/999 [04:50<11:51,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18667941690597947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 320/999 [05:00<10:13,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1865318941987045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 330/999 [05:08<09:30,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18680984273107482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 340/999 [05:18<09:17,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18440848350861275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 350/999 [05:28<09:55,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18746631726205748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 360/999 [05:38<10:54,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18741782893898842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 370/999 [05:47<09:46,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18879923058694867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 380/999 [05:57<10:49,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18633809605814242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 390/999 [06:09<11:03,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18491100050616313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/999 [06:17<08:25,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18824828895029092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 410/999 [06:29<09:21,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18772791691939064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 420/999 [06:38<08:13,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18636809388440026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 430/999 [06:48<08:30,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18506523358020766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 440/999 [06:58<08:15,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18901084965650025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 450/999 [07:07<09:38,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19091461304418347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 460/999 [07:16<07:23,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19093687087705882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 470/999 [07:26<07:43,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19161704129921028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 480/999 [07:37<10:16,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19217030237552324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 490/999 [07:49<09:41,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1903833009492821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/999 [07:59<08:59,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18925162851952823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 510/999 [08:07<06:20,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19048575086262035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 520/999 [08:14<05:20,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19198560940353449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 530/999 [08:23<07:46,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1927518828664846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 540/999 [08:34<08:19,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19166605034440887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 550/999 [08:43<07:09,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19170759664049383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 560/999 [08:52<06:15,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19325423166094033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 570/999 [09:03<07:47,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19286291815178014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 580/999 [09:12<05:49,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19231305891383046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 590/999 [09:21<06:40,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1903961006303781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 600/999 [09:30<05:35,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1914733835454111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 610/999 [09:42<06:38,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19085021516366302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 620/999 [09:51<05:59,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19194588213467093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 630/999 [10:02<06:35,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19086871141524575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 640/999 [10:11<04:56,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1914082214528453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 650/999 [10:22<05:28,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19312035539764694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 660/999 [10:32<05:17,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19233964790694924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 670/999 [10:42<05:16,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19273366323892224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 680/999 [10:53<05:58,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1914008215313536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 690/999 [11:05<05:17,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19054501140950603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 700/999 [11:18<06:18,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18977498087672875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 710/999 [11:29<05:22,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19066417779673725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 720/999 [11:37<03:39,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19056782235643668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 730/999 [11:48<05:22,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19095687046064266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 740/999 [12:00<05:16,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.18946262673462827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 750/999 [12:13<05:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19119029909229107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 760/999 [12:24<04:22,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19031761410923811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 770/999 [12:36<04:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.189236320566185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 780/999 [12:48<04:12,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19149928775939254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 790/999 [13:02<04:15,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19087527322704737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/999 [13:12<03:16,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1915461669279174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 810/999 [13:24<03:57,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19125621303195195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 820/999 [13:35<02:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19287886886929986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 830/999 [13:47<03:39,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19343868949450002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 840/999 [13:58<02:40,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19444925787302864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 850/999 [14:08<02:16,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19536344778811504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 860/999 [14:18<02:10,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19673736682557913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 870/999 [14:29<02:23,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19634836891948573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 880/999 [14:41<02:12,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1961829524121267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 890/999 [14:55<02:21,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19664552672378396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/999 [15:07<01:44,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1955146456899403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 910/999 [15:20<01:42,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19474689775919207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 920/999 [15:33<01:45,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19505697293613194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 930/999 [15:44<01:18,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19525565170868317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 940/999 [15:55<01:09,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19433435718179717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 950/999 [16:05<00:47,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.1937264542769346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 960/999 [16:18<00:53,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19380896557021465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 970/999 [16:29<00:34,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19359048828943992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 980/999 [16:42<00:25,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19361818466644573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 990/999 [16:55<00:10,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.19329006936191737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [17:03<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "candidate = []\n",
    "real = []\n",
    "\n",
    "max_len = 128\n",
    "\n",
    "# pad : 0 / start : 1 / end : 2 / unk : 3\n",
    "\n",
    "for a,b in zip(tqdm(test_en_final),test_ge_final):\n",
    "    enc_qus = a\n",
    "    real_qus = b\n",
    "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "    \n",
    "    question.to(device)\n",
    "    real_qus.to(device)\n",
    "    transformer.to(device)\n",
    "    \n",
    "    question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)\n",
    "    sentence = beam_search(transformer, question, question_mask, int(max_len), dict)\n",
    "    \n",
    "    c = [bb[i] for i in sentence if (i != 0) and (i != 1) and (i != 2)]\n",
    "    r = [bb[i.tolist()] for i in real_qus if (i.tolist() != 0) and (i.tolist() != 1)  and (i != 2)]\n",
    "    \n",
    "    candidate.append(c)\n",
    "    real.append(r)\n",
    "    \n",
    "    data = 0\n",
    "    \n",
    "    for i,j in zip(real,candidate):\n",
    "        data += bleu.sentence_bleu([i],j,weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method1)\n",
    "        \n",
    "        \n",
    "    if len(real) % 10  == 0:\n",
    "        print('BLEU -4 score : ', data / len(real))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BLEU -4 score :  0.19319376051847126\n"
     ]
    }
   ],
   "source": [
    "print('Final BLEU -4 score : ', data / len(real))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 끝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
