{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bentrevett/multi30k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\Pray\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset.map(lambda e: tokenizer(e['en'], padding= False), batched=True)\n",
    "dataset3 = dataset.map(lambda e: tokenizer(e['de'], padding= False), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58101 # 이를 start token으로 지정.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique([len(i) for i in dataset2['train']['input_ids']]), np.unique([len(i) for i in dataset3['train']['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences_en(sequences):\n",
    "    max_len = 128\n",
    "    padded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) >= max_len:\n",
    "            padded_sequence = sequence[:max_len]  # 최대 길이까지 잘라냄\n",
    "        else:\n",
    "            padded_sequence = sequence + [58100] * (max_len - len(sequence))  # 패딩 추가\n",
    "        padded_sequences.append(padded_sequence)\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences_de(sequences):\n",
    "    max_len = 128\n",
    "    padded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) >= max_len:\n",
    "            padded_sequence = [58101] + sequence[:max_len-1]  # 최대 길이까지 잘라냄\n",
    "        else:\n",
    "            padded_sequence = [58101] + sequence + [58100] * (max_len - len(sequence) - 1)  # 패딩 추가\n",
    "        padded_sequences.append(padded_sequence)\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_batch = pad_sequences(dataset2['train']['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en, train_ge = torch.tensor(pad_sequences_en(dataset2['train']['input_ids'])), torch.tensor(pad_sequences_de(dataset3['train']['input_ids']))\n",
    "valid_en, valid_ge = torch.tensor(pad_sequences_en(dataset2['validation']['input_ids'])), torch.tensor(pad_sequences_de(dataset3['validation']['input_ids']))\n",
    "test_en, test_ge = torch.tensor(pad_sequences_en(dataset2['test']['input_ids'])), torch.tensor(pad_sequences_de(dataset3['test']['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58101,   589,  7554,  7861, 22012,    95,   197,  5192,    18, 17694,\n",
       "           34,   731,  7199,    82,    49,  4407,    15,     5,     9,   394,\n",
       "         1258,  1578,  5154,   526,    45, 14243,  3351,     3,     0, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ge[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({128}, {128})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([len(i) for i in train_en]), set([len(i) for i in train_ge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, inputs, output):\n",
    "\n",
    "        self.inputs = inputs\n",
    "        self.output = output\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        inputs = self.inputs[idx]\n",
    "        output = self.output[idx]\n",
    "        \n",
    "        return inputs, output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_en, train_ge)\n",
    "valid_dataset = Dataset(valid_en, valid_ge)\n",
    "test_dataset = Dataset(test_en, test_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = False, drop_last = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 64, shuffle = False, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, max_len = 128):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.embed = nn.Embedding(vocab_size + 1, d_model)\n",
    "        self.pe = self.create_positinal_encoding(max_len, self.d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def create_positinal_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        for pos in range(max_len):  \n",
    "            for i in range(0, d_model, 2):  \n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)  \n",
    "        return pe\n",
    "\n",
    "    def forward(self, encoded_words):\n",
    "        \n",
    "        embedding = self.embed(encoded_words) * torch.sqrt(torch.tensor(self.d_model)).to(device)\n",
    "        embedding += self.pe[:, :embedding.size(1)]   \n",
    "        embedding = self.dropout(embedding)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attention(nn.Module):\n",
    "    \n",
    "#     def __init__(self, embedding_size = 512):\n",
    "        \n",
    "#         self.data = data\n",
    "#         self.embedding_size= embedding_size\n",
    "#         self.weight_Q = nn.Linear(embedding_size, embedding_size)\n",
    "#         self.weight_K = nn.Linear(embedding_size, embedding_size)\n",
    "#         self.weight_V = nn.Linear(embedding_size, embedding_size)\n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "#     def forward(self, data):\n",
    "        \n",
    "#         Q = self.weight_Q(data)\n",
    "#         K = self.weight_K(data)\n",
    "#         V = self.weight_V(data)\n",
    "#         score = torch.matmul(Q,K.T) / torch.sqrt(self.embedding_size)\n",
    "#         value = self.softmax(score) * V\n",
    "#         return value\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inputs, outputs_input, outputs_target):\n",
    "    \n",
    "    def subsequent_mask(size):\n",
    "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype = torch.uint8)\n",
    "        return mask.unsqueeze(0) # 상삼각행렬 생성 -> 행과 열을 뒤 바꾸어 하삼각행렬로 바꿈. (밑에가 다 0)\n",
    "    \n",
    "    inputs_mask = inputs != 58100\n",
    "    inputs_mask = inputs_mask.to(device)\n",
    "    inputs_mask = inputs_mask.unsqueeze(1).unsqueeze(1) # 각  input에 대해서 상삼각행렬에 대응하도록 설정.\n",
    "    \n",
    "    outputs_input_mask = outputs_input != 58100\n",
    "    outputs_input_mask = outputs_input_mask.unsqueeze(1) \n",
    "    outputs_input_mask = outputs_input_mask & subsequent_mask(outputs_input.size(-1)).type_as(outputs_input_mask.data)\n",
    "    outputs_input_mask = outputs_input_mask.unsqueeze(1)\n",
    "    # masking을 해줌으로서, \n",
    "\n",
    "    \n",
    "    outputs_target_mask = outputs_target != 58100\n",
    "    \n",
    "    return inputs_mask, outputs_input_mask, outputs_target_mask\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4386,  1296,     2,  ..., 58100, 58100, 58100],\n",
       "        [15036,  1135,     5,  ..., 58100, 58100, 58100],\n",
       "        [   93,   839,  4040,  ..., 58100, 58100, 58100],\n",
       "        ...,\n",
       "        [ 4386,  8722,  2013,  ..., 58100, 58100, 58100],\n",
       "        [  282, 17525,   175,  ..., 58100, 58100, 58100],\n",
       "        [   93,   175,     5,  ..., 58100, 58100, 58100]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key  = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.concat = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, query, key, value, mask):\n",
    "        \n",
    "        query = self.query(query)\n",
    "        key = self.key(key)\n",
    "        value = self.value(value)\n",
    "        \n",
    "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        \n",
    "\n",
    "        scores = torch.matmul(query, key.permute(0 ,1 ,3, 2)) / math.sqrt(query.size(-1))\n",
    "        \n",
    "        # print(query.shape, key.shape, value.shape, mask.shape, scores.shape)\n",
    "\n",
    "        \n",
    "        scores = scores.masked_fill(mask == 0, -1e9) # masking 된 것에 매우 작은 수 부여 -> softmax 계산시 -inf 로 계산되어짐.\n",
    "        weights = F.softmax(scores, dim = -1) # attention score 계산\n",
    "        context = torch.matmul(weights, value)  # attention value 계산\n",
    "        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
    "        \n",
    "        interacted = self.concat(context)\n",
    "        \n",
    "        return interacted\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, middle_dim = 2048):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, embeddings, mask):\n",
    "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
    "        interacted = self.layernorm(interacted + embeddings)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        encoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return encoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.src_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
    "        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n",
    "        query = self.layernorm(query + embeddings)\n",
    "        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n",
    "        interacted = self.layernorm(interacted + query)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        decoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P_Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, vocab_size):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size + 1\n",
    "        self.embed = Embeddings(self.vocab_size, d_model)\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_words, src_mask):\n",
    "        src_embeddings = self.embed(src_words)\n",
    "        encoded_layers = []\n",
    "        for layer in self.encoder:\n",
    "            src_embeddings = layer(src_embeddings, src_mask)\n",
    "            encoded_layers.append(src_embeddings)\n",
    "            \n",
    "        return encoded_layers\n",
    "\n",
    "    def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
    "        tgt_embeddings = self.embed(target_words)\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            tgt_embeddings = layer(tgt_embeddings, src_embeddings[i], src_mask, target_mask)\n",
    "            decoded_layers.append(tgt_embeddings)\n",
    "        return tgt_embeddings\n",
    "\n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded_layers = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded_layers, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, vocab_size):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size + 1\n",
    "        self.embed = Embeddings(self.vocab_size, d_model)\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_words, src_mask):\n",
    "        src_embeddings = self.embed(src_words)\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            src_embeddings = layer(src_embeddings, src_mask)\n",
    "            \n",
    "        return src_embeddings\n",
    "\n",
    "    def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
    "        tgt_embeddings = self.embed(target_words)\n",
    "        for layer in self.decoder:\n",
    "            tgt_embeddings = layer(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "\n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamWarmup:\n",
    "    \n",
    "    def __init__(self, model_size, warmup_steps, optimizer):\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        self.current_step = 0\n",
    "        self.lr = 0\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        self.current_step += 1\n",
    "        lr = self.get_lr()\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "        self.lr = lr\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LossWithLS(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, smooth):\n",
    "        super(LossWithLS, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, prediction, target, mask):\n",
    "        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n",
    "        target = target.contiguous().view(-1)   # (batch_size * max_words)\n",
    "        mask = mask.float()\n",
    "        mask = mask.view(-1)       # (batch_size * max_words)\n",
    "        \n",
    "        # Smoothed one-hot labels\n",
    "        labels = torch.full_like(prediction, self.smooth / (self.size - 1))\n",
    "        labels.scatter_(1, target.unsqueeze(1), 1 - self.smooth)\n",
    "        \n",
    "        # Apply mask\n",
    "        masked_prediction = prediction * mask.unsqueeze(1)\n",
    "        masked_labels = labels * mask.unsqueeze(1)\n",
    "\n",
    "        \n",
    "        # Calculate negative log likelihood loss\n",
    "        loss = F.nll_loss(masked_prediction, target, reduction='none')\n",
    "        loss *= mask\n",
    "        \n",
    "        # Normalize the loss\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "heads = 8\n",
    "num_layers = 6\n",
    "num_layers = 6\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "vocab_len = len(tokenizer.get_vocab())\n",
    "\n",
    "transformer = Transformer(d_model = d_model , heads = heads, num_layers = num_layers, vocab_size = vocab_len)\n",
    "transformer = transformer.to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters())\n",
    "transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(vocab_len, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader.dataset))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def generate_next_words(transformer, sequence, encoded, question_mask, beam_width):\n",
    "    \n",
    "    start_token = 58101\n",
    "    \n",
    "    if not sequence:\n",
    "        return [(start_token, 0)]\n",
    "    \n",
    "    size = len(sequence)\n",
    "    target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "    target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    words = torch.LongTensor([sequence]).to(device)\n",
    "\n",
    "    decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
    "    predictions = transformer.logit(decoded[:, -1])\n",
    "\n",
    "    # Apply log_softmax\n",
    "    log_probs = F.log_softmax(predictions, dim = -1)\n",
    "\n",
    "    # Get top-k words\n",
    "    top_k_probs, top_k_indices = torch.topk(log_probs, beam_width, dim=-1)\n",
    "    top_k_probs = top_k_probs.squeeze().tolist()\n",
    "    top_k_indices = top_k_indices.squeeze().tolist()\n",
    "\n",
    "    next_words = [(word, prob) for word, prob in zip(top_k_indices, top_k_probs)]\n",
    "    return next_words\n",
    "\n",
    "\n",
    "def beam_search(transformer, question, question_mask, max_len, dict, beam_width=5):\n",
    "    transformer.eval()\n",
    "    start_token = 58101\n",
    "    end_token = 0\n",
    "\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "\n",
    "    beams = [([], 0)] \n",
    "\n",
    "    for step in range(max_len):\n",
    "        candidates = []\n",
    "\n",
    "        for seq, score in beams:\n",
    "            if seq and seq[-1] == end_token:\n",
    "                candidates.append((seq, score))\n",
    "                continue\n",
    "            \n",
    "            next_words = generate_next_words(transformer, seq, encoded, question_mask, beam_width)\n",
    "\n",
    "            for word, log_prob in next_words:\n",
    "                candidates.append((seq + [word], score + log_prob))\n",
    "\n",
    "        # Select top-k candidates\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        beams = candidates[:beam_width]\n",
    "\n",
    "        # Check if all beams have ended\n",
    "        if all(seq[-1] == end_token for seq, _ in beams):\n",
    "            break\n",
    "\n",
    "    best_seq, _ = max(beams, key=lambda x: x[1])\n",
    "    return best_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoon303b\u001b[0m (\u001b[33mku_software\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\USER\\Documents\\Jupyter_Notebook\\Graduate_중앙대\\Second\\wandb\\run-20240426_113635-g3rn74y9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ku_software/Transformer_Hard_Coding/runs/g3rn74y9' target=\"_blank\">earthy-dream-27</a></strong> to <a href='https://wandb.ai/ku_software/Transformer_Hard_Coding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ku_software/Transformer_Hard_Coding' target=\"_blank\">https://wandb.ai/ku_software/Transformer_Hard_Coding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ku_software/Transformer_Hard_Coding/runs/g3rn74y9' target=\"_blank\">https://wandb.ai/ku_software/Transformer_Hard_Coding/runs/g3rn74y9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ku_software/Transformer_Hard_Coding/runs/g3rn74y9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ccfdc0b650>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Transformer_Hard_Coding\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"loss\": 'KLDivergence',\n",
    "    \"architecture\": \"Transformer\",\n",
    "    \"optimizer\" : 'AdamWarmup',\n",
    "    'layer' : 6,\n",
    "    'heads' : 8,\n",
    "    'd_model' : 64   \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = {v:k for k,v in tokenizer.get_vocab().items()} \n",
    "bb[58101] = '<start>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, transformer, criterion, epoch):\n",
    "    \n",
    "    transformer.train()\n",
    "    sum_loss, valid_sum_loss = 0, 0\n",
    "    count, valid_count = 0, 0\n",
    "    \n",
    "    for i, (inputs, output) in enumerate(train_loader):\n",
    "        \n",
    "        samples = inputs.shape[0]\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        output = output.to(device)\n",
    "        \n",
    "        output_in = output[:,:-1]\n",
    "        output_target = output[:,1:]\n",
    "        inputs_mask, output_in_mask, output_target_mask = create_masks(inputs, output_in, output_target)\n",
    "        \n",
    "        out = transformer(inputs, inputs_mask, output_in, output_in_mask)\n",
    "        \n",
    "        loss = criterion(out, output_target, output_target_mask)\n",
    "        transformer_optimizer.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        transformer_optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item() * samples\n",
    "        count += samples\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(\"Epoch [{}][{}/{}]\\tTrain Loss: {:.3f}\".format(epoch, i, len(train_loader), sum_loss/count))\n",
    "            wandb.log({\"Training loss\" : sum_loss/count})\n",
    "    \n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, output) in enumerate(valid_loader):\n",
    "            \n",
    "            samples = inputs.shape[0]\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            output = output.to(device)\n",
    "            \n",
    "            output_in = output[:,:-1]\n",
    "            output_target = output[:,1:]\n",
    "            \n",
    "            inputs_mask, output_in_mask, output_target_mask = create_masks(inputs, output_in, output_target)\n",
    "            out = transformer(inputs, inputs_mask, output_in, output_in_mask)\n",
    "            \n",
    "            loss = criterion(out, output_target, output_target_mask)\n",
    "            \n",
    "            valid_sum_loss += loss.item() * samples\n",
    "            valid_count += samples\n",
    "        \n",
    "            if i % 5   == 0:\n",
    "                print(\"Epoch [{}][{}/{}]\\t\\t\\tValid Loss: {:.3f}\".format(epoch, i, len(valid_loader), valid_sum_loss/valid_count))\n",
    "                wandb.log({\"Validation loss\" :  valid_sum_loss/valid_count })\n",
    "                \n",
    "\n",
    "    max_len = 128\n",
    "    A = random.randint(1, 64)\n",
    "    B = next(iter(test_loader))\n",
    "    \n",
    "    enc_qus = B[0][A]\n",
    "    real_qus = B[1][A]\n",
    "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "    question_mask = (question!=58100).to(device).unsqueeze(1).unsqueeze(1)\n",
    "    sentence = beam_search(transformer, question, question_mask, int(max_len), dict)\n",
    "    \n",
    "    candidate = [bb[i] for i in sentence if (i != 0) and (i != 58100) and (i != 58101)]\n",
    "    real = [bb[i.tolist()] for i in real_qus if (i.tolist() != 0) and (i.tolist() != 58100)  and (i != 58101)]\n",
    "    print()\n",
    "    print('Candidate :'  + ' '.join(candidate))\n",
    "    print('Candidate_labeled : ', [bb[i] for i in sentence])\n",
    "    print('Real :' + ' '.join(real))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 724.0773, 1448.1547, 1448.1547])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor((64, 128, 128)) * math.sqrt(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_en, train_ge)\n",
    "valid_dataset = Dataset(valid_en, valid_ge)\n",
    "test_dataset = Dataset(test_en, test_ge)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True, drop_last = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 64, shuffle = True, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random.randint(1, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][0/453]\tTrain Loss: 1.562\n",
      "Epoch [0][5/453]\tTrain Loss: 1.429\n",
      "Epoch [0][10/453]\tTrain Loss: 1.419\n",
      "Epoch [0][15/453]\tTrain Loss: 1.412\n",
      "Epoch [0][20/453]\tTrain Loss: 1.405\n",
      "Epoch [0][25/453]\tTrain Loss: 1.406\n",
      "Epoch [0][30/453]\tTrain Loss: 1.405\n",
      "Epoch [0][35/453]\tTrain Loss: 1.408\n",
      "Epoch [0][40/453]\tTrain Loss: 1.415\n",
      "Epoch [0][45/453]\tTrain Loss: 1.412\n",
      "Epoch [0][50/453]\tTrain Loss: 1.409\n",
      "Epoch [0][55/453]\tTrain Loss: 1.410\n",
      "Epoch [0][60/453]\tTrain Loss: 1.409\n",
      "Epoch [0][65/453]\tTrain Loss: 1.415\n",
      "Epoch [0][70/453]\tTrain Loss: 1.418\n",
      "Epoch [0][75/453]\tTrain Loss: 1.420\n",
      "Epoch [0][80/453]\tTrain Loss: 1.420\n",
      "Epoch [0][85/453]\tTrain Loss: 1.420\n",
      "Epoch [0][90/453]\tTrain Loss: 1.421\n",
      "Epoch [0][95/453]\tTrain Loss: 1.420\n",
      "Epoch [0][100/453]\tTrain Loss: 1.426\n",
      "Epoch [0][105/453]\tTrain Loss: 1.428\n",
      "Epoch [0][110/453]\tTrain Loss: 1.425\n",
      "Epoch [0][115/453]\tTrain Loss: 1.427\n",
      "Epoch [0][120/453]\tTrain Loss: 1.427\n",
      "Epoch [0][125/453]\tTrain Loss: 1.427\n",
      "Epoch [0][130/453]\tTrain Loss: 1.430\n",
      "Epoch [0][135/453]\tTrain Loss: 1.428\n",
      "Epoch [0][140/453]\tTrain Loss: 1.430\n",
      "Epoch [0][145/453]\tTrain Loss: 1.431\n",
      "Epoch [0][150/453]\tTrain Loss: 1.431\n",
      "Epoch [0][155/453]\tTrain Loss: 1.431\n",
      "Epoch [0][160/453]\tTrain Loss: 1.432\n",
      "Epoch [0][165/453]\tTrain Loss: 1.433\n",
      "Epoch [0][170/453]\tTrain Loss: 1.434\n",
      "Epoch [0][175/453]\tTrain Loss: 1.436\n",
      "Epoch [0][180/453]\tTrain Loss: 1.436\n",
      "Epoch [0][185/453]\tTrain Loss: 1.435\n",
      "Epoch [0][190/453]\tTrain Loss: 1.436\n",
      "Epoch [0][195/453]\tTrain Loss: 1.437\n",
      "Epoch [0][200/453]\tTrain Loss: 1.436\n",
      "Epoch [0][205/453]\tTrain Loss: 1.437\n",
      "Epoch [0][210/453]\tTrain Loss: 1.438\n",
      "Epoch [0][215/453]\tTrain Loss: 1.438\n",
      "Epoch [0][220/453]\tTrain Loss: 1.439\n",
      "Epoch [0][225/453]\tTrain Loss: 1.440\n",
      "Epoch [0][230/453]\tTrain Loss: 1.442\n",
      "Epoch [0][235/453]\tTrain Loss: 1.443\n",
      "Epoch [0][240/453]\tTrain Loss: 1.444\n",
      "Epoch [0][245/453]\tTrain Loss: 1.444\n",
      "Epoch [0][250/453]\tTrain Loss: 1.444\n",
      "Epoch [0][255/453]\tTrain Loss: 1.443\n",
      "Epoch [0][260/453]\tTrain Loss: 1.443\n",
      "Epoch [0][265/453]\tTrain Loss: 1.445\n",
      "Epoch [0][270/453]\tTrain Loss: 1.445\n",
      "Epoch [0][275/453]\tTrain Loss: 1.445\n",
      "Epoch [0][280/453]\tTrain Loss: 1.445\n",
      "Epoch [0][285/453]\tTrain Loss: 1.445\n",
      "Epoch [0][290/453]\tTrain Loss: 1.446\n",
      "Epoch [0][295/453]\tTrain Loss: 1.447\n",
      "Epoch [0][300/453]\tTrain Loss: 1.446\n",
      "Epoch [0][305/453]\tTrain Loss: 1.447\n",
      "Epoch [0][310/453]\tTrain Loss: 1.447\n",
      "Epoch [0][315/453]\tTrain Loss: 1.447\n",
      "Epoch [0][320/453]\tTrain Loss: 1.447\n",
      "Epoch [0][325/453]\tTrain Loss: 1.447\n",
      "Epoch [0][330/453]\tTrain Loss: 1.447\n",
      "Epoch [0][335/453]\tTrain Loss: 1.448\n",
      "Epoch [0][340/453]\tTrain Loss: 1.448\n",
      "Epoch [0][345/453]\tTrain Loss: 1.449\n",
      "Epoch [0][350/453]\tTrain Loss: 1.449\n",
      "Epoch [0][355/453]\tTrain Loss: 1.449\n",
      "Epoch [0][360/453]\tTrain Loss: 1.450\n",
      "Epoch [0][365/453]\tTrain Loss: 1.449\n",
      "Epoch [0][370/453]\tTrain Loss: 1.450\n",
      "Epoch [0][375/453]\tTrain Loss: 1.450\n",
      "Epoch [0][380/453]\tTrain Loss: 1.450\n",
      "Epoch [0][385/453]\tTrain Loss: 1.450\n",
      "Epoch [0][390/453]\tTrain Loss: 1.449\n",
      "Epoch [0][395/453]\tTrain Loss: 1.450\n",
      "Epoch [0][400/453]\tTrain Loss: 1.450\n",
      "Epoch [0][405/453]\tTrain Loss: 1.450\n",
      "Epoch [0][410/453]\tTrain Loss: 1.451\n",
      "Epoch [0][415/453]\tTrain Loss: 1.450\n",
      "Epoch [0][420/453]\tTrain Loss: 1.451\n",
      "Epoch [0][425/453]\tTrain Loss: 1.451\n",
      "Epoch [0][430/453]\tTrain Loss: 1.451\n",
      "Epoch [0][435/453]\tTrain Loss: 1.451\n",
      "Epoch [0][440/453]\tTrain Loss: 1.453\n",
      "Epoch [0][445/453]\tTrain Loss: 1.453\n",
      "Epoch [0][450/453]\tTrain Loss: 1.454\n",
      "Epoch [0][0/15]\t\t\tValid Loss: 1.626\n",
      "Epoch [0][5/15]\t\t\tValid Loss: 1.577\n",
      "Epoch [0][10/15]\t\t\tValid Loss: 1.621\n",
      "\n",
      "Candidate :▁Ein ▁Kind ▁plans cht ▁im ▁Wasser .\n",
      "Candidate_labeled :  ['<start>', '▁Ein', '▁Kind', '▁plans', 'cht', '▁im', '▁Wasser', '.', '</s>']\n",
      "Real :▁Ein ▁Kind ▁plans cht ▁im ▁Wasser .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:09:21.487820 #######\n",
      "\n",
      "Epoch [1][0/453]\tTrain Loss: 1.386\n",
      "Epoch [1][5/453]\tTrain Loss: 1.353\n",
      "Epoch [1][10/453]\tTrain Loss: 1.363\n",
      "Epoch [1][15/453]\tTrain Loss: 1.365\n",
      "Epoch [1][20/453]\tTrain Loss: 1.353\n",
      "Epoch [1][25/453]\tTrain Loss: 1.377\n",
      "Epoch [1][30/453]\tTrain Loss: 1.367\n",
      "Epoch [1][35/453]\tTrain Loss: 1.381\n",
      "Epoch [1][40/453]\tTrain Loss: 1.379\n",
      "Epoch [1][45/453]\tTrain Loss: 1.380\n",
      "Epoch [1][50/453]\tTrain Loss: 1.375\n",
      "Epoch [1][55/453]\tTrain Loss: 1.380\n",
      "Epoch [1][60/453]\tTrain Loss: 1.382\n",
      "Epoch [1][65/453]\tTrain Loss: 1.385\n",
      "Epoch [1][70/453]\tTrain Loss: 1.386\n",
      "Epoch [1][75/453]\tTrain Loss: 1.388\n",
      "Epoch [1][80/453]\tTrain Loss: 1.388\n",
      "Epoch [1][85/453]\tTrain Loss: 1.384\n",
      "Epoch [1][90/453]\tTrain Loss: 1.388\n",
      "Epoch [1][95/453]\tTrain Loss: 1.384\n",
      "Epoch [1][100/453]\tTrain Loss: 1.385\n",
      "Epoch [1][105/453]\tTrain Loss: 1.387\n",
      "Epoch [1][110/453]\tTrain Loss: 1.387\n",
      "Epoch [1][115/453]\tTrain Loss: 1.385\n",
      "Epoch [1][120/453]\tTrain Loss: 1.385\n",
      "Epoch [1][125/453]\tTrain Loss: 1.386\n",
      "Epoch [1][130/453]\tTrain Loss: 1.388\n",
      "Epoch [1][135/453]\tTrain Loss: 1.388\n",
      "Epoch [1][140/453]\tTrain Loss: 1.390\n",
      "Epoch [1][145/453]\tTrain Loss: 1.391\n",
      "Epoch [1][150/453]\tTrain Loss: 1.387\n",
      "Epoch [1][155/453]\tTrain Loss: 1.389\n",
      "Epoch [1][160/453]\tTrain Loss: 1.391\n",
      "Epoch [1][165/453]\tTrain Loss: 1.393\n",
      "Epoch [1][170/453]\tTrain Loss: 1.393\n",
      "Epoch [1][175/453]\tTrain Loss: 1.392\n",
      "Epoch [1][180/453]\tTrain Loss: 1.393\n",
      "Epoch [1][185/453]\tTrain Loss: 1.394\n",
      "Epoch [1][190/453]\tTrain Loss: 1.394\n",
      "Epoch [1][195/453]\tTrain Loss: 1.394\n",
      "Epoch [1][200/453]\tTrain Loss: 1.393\n",
      "Epoch [1][205/453]\tTrain Loss: 1.393\n",
      "Epoch [1][210/453]\tTrain Loss: 1.394\n",
      "Epoch [1][215/453]\tTrain Loss: 1.394\n",
      "Epoch [1][220/453]\tTrain Loss: 1.394\n",
      "Epoch [1][225/453]\tTrain Loss: 1.395\n",
      "Epoch [1][230/453]\tTrain Loss: 1.395\n",
      "Epoch [1][235/453]\tTrain Loss: 1.395\n",
      "Epoch [1][240/453]\tTrain Loss: 1.395\n",
      "Epoch [1][245/453]\tTrain Loss: 1.396\n",
      "Epoch [1][250/453]\tTrain Loss: 1.396\n",
      "Epoch [1][255/453]\tTrain Loss: 1.396\n",
      "Epoch [1][260/453]\tTrain Loss: 1.398\n",
      "Epoch [1][265/453]\tTrain Loss: 1.397\n",
      "Epoch [1][270/453]\tTrain Loss: 1.397\n",
      "Epoch [1][275/453]\tTrain Loss: 1.398\n",
      "Epoch [1][280/453]\tTrain Loss: 1.399\n",
      "Epoch [1][285/453]\tTrain Loss: 1.399\n",
      "Epoch [1][290/453]\tTrain Loss: 1.399\n",
      "Epoch [1][295/453]\tTrain Loss: 1.399\n",
      "Epoch [1][300/453]\tTrain Loss: 1.398\n",
      "Epoch [1][305/453]\tTrain Loss: 1.399\n",
      "Epoch [1][310/453]\tTrain Loss: 1.399\n",
      "Epoch [1][315/453]\tTrain Loss: 1.399\n",
      "Epoch [1][320/453]\tTrain Loss: 1.399\n",
      "Epoch [1][325/453]\tTrain Loss: 1.399\n",
      "Epoch [1][330/453]\tTrain Loss: 1.399\n",
      "Epoch [1][335/453]\tTrain Loss: 1.400\n",
      "Epoch [1][340/453]\tTrain Loss: 1.400\n",
      "Epoch [1][345/453]\tTrain Loss: 1.401\n",
      "Epoch [1][350/453]\tTrain Loss: 1.401\n",
      "Epoch [1][355/453]\tTrain Loss: 1.401\n",
      "Epoch [1][360/453]\tTrain Loss: 1.401\n",
      "Epoch [1][365/453]\tTrain Loss: 1.402\n",
      "Epoch [1][370/453]\tTrain Loss: 1.403\n",
      "Epoch [1][375/453]\tTrain Loss: 1.403\n",
      "Epoch [1][380/453]\tTrain Loss: 1.402\n",
      "Epoch [1][385/453]\tTrain Loss: 1.402\n",
      "Epoch [1][390/453]\tTrain Loss: 1.403\n",
      "Epoch [1][395/453]\tTrain Loss: 1.403\n",
      "Epoch [1][400/453]\tTrain Loss: 1.403\n",
      "Epoch [1][405/453]\tTrain Loss: 1.404\n",
      "Epoch [1][410/453]\tTrain Loss: 1.403\n",
      "Epoch [1][415/453]\tTrain Loss: 1.404\n",
      "Epoch [1][420/453]\tTrain Loss: 1.404\n",
      "Epoch [1][425/453]\tTrain Loss: 1.404\n",
      "Epoch [1][430/453]\tTrain Loss: 1.404\n",
      "Epoch [1][435/453]\tTrain Loss: 1.405\n",
      "Epoch [1][440/453]\tTrain Loss: 1.405\n",
      "Epoch [1][445/453]\tTrain Loss: 1.405\n",
      "Epoch [1][450/453]\tTrain Loss: 1.406\n",
      "Epoch [1][0/15]\t\t\tValid Loss: 1.698\n",
      "Epoch [1][5/15]\t\t\tValid Loss: 1.558\n",
      "Epoch [1][10/15]\t\t\tValid Loss: 1.599\n",
      "\n",
      "Candidate :▁E ine ▁Frau ▁in ▁ein er ▁sch war zen ▁M ütz e ▁und ▁gr au en ▁Kap pe ▁ste h t ▁an ▁eine m ▁Ge sch ä ft markt .\n",
      "Candidate_labeled :  ['<start>', '▁E', 'ine', '▁Frau', '▁in', '▁ein', 'er', '▁sch', 'war', 'zen', '▁M', 'ütz', 'e', '▁und', '▁gr', 'au', 'en', '▁Kap', 'pe', '▁ste', 'h', 't', '▁an', '▁eine', 'm', '▁Ge', 'sch', 'ä', 'ft', 'markt', '.', '</s>']\n",
      "Real :▁E ine ▁Frau ▁in ▁eine m ▁Gra u en ▁Pull i ▁und ▁mit ▁ein er ▁sch war zen ▁Base ball m ütz e ▁ste h t ▁in ▁eine m ▁Ge sch ä ft ▁in ▁der ▁Sch lange .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:09:08.684576 #######\n",
      "\n",
      "Epoch [2][0/453]\tTrain Loss: 1.369\n",
      "Epoch [2][5/453]\tTrain Loss: 1.344\n",
      "Epoch [2][10/453]\tTrain Loss: 1.323\n",
      "Epoch [2][15/453]\tTrain Loss: 1.326\n",
      "Epoch [2][20/453]\tTrain Loss: 1.323\n",
      "Epoch [2][25/453]\tTrain Loss: 1.323\n",
      "Epoch [2][30/453]\tTrain Loss: 1.327\n",
      "Epoch [2][35/453]\tTrain Loss: 1.321\n",
      "Epoch [2][40/453]\tTrain Loss: 1.326\n",
      "Epoch [2][45/453]\tTrain Loss: 1.320\n",
      "Epoch [2][50/453]\tTrain Loss: 1.321\n",
      "Epoch [2][55/453]\tTrain Loss: 1.328\n",
      "Epoch [2][60/453]\tTrain Loss: 1.326\n",
      "Epoch [2][65/453]\tTrain Loss: 1.325\n",
      "Epoch [2][70/453]\tTrain Loss: 1.330\n",
      "Epoch [2][75/453]\tTrain Loss: 1.328\n",
      "Epoch [2][80/453]\tTrain Loss: 1.332\n",
      "Epoch [2][85/453]\tTrain Loss: 1.335\n",
      "Epoch [2][90/453]\tTrain Loss: 1.334\n",
      "Epoch [2][95/453]\tTrain Loss: 1.338\n",
      "Epoch [2][100/453]\tTrain Loss: 1.342\n",
      "Epoch [2][105/453]\tTrain Loss: 1.342\n",
      "Epoch [2][110/453]\tTrain Loss: 1.343\n",
      "Epoch [2][115/453]\tTrain Loss: 1.341\n",
      "Epoch [2][120/453]\tTrain Loss: 1.342\n",
      "Epoch [2][125/453]\tTrain Loss: 1.342\n",
      "Epoch [2][130/453]\tTrain Loss: 1.346\n",
      "Epoch [2][135/453]\tTrain Loss: 1.343\n",
      "Epoch [2][140/453]\tTrain Loss: 1.343\n",
      "Epoch [2][145/453]\tTrain Loss: 1.343\n",
      "Epoch [2][150/453]\tTrain Loss: 1.343\n",
      "Epoch [2][155/453]\tTrain Loss: 1.342\n",
      "Epoch [2][160/453]\tTrain Loss: 1.344\n",
      "Epoch [2][165/453]\tTrain Loss: 1.343\n",
      "Epoch [2][170/453]\tTrain Loss: 1.344\n",
      "Epoch [2][175/453]\tTrain Loss: 1.344\n",
      "Epoch [2][180/453]\tTrain Loss: 1.345\n",
      "Epoch [2][185/453]\tTrain Loss: 1.345\n",
      "Epoch [2][190/453]\tTrain Loss: 1.346\n",
      "Epoch [2][195/453]\tTrain Loss: 1.348\n",
      "Epoch [2][200/453]\tTrain Loss: 1.348\n",
      "Epoch [2][205/453]\tTrain Loss: 1.350\n",
      "Epoch [2][210/453]\tTrain Loss: 1.350\n",
      "Epoch [2][215/453]\tTrain Loss: 1.352\n",
      "Epoch [2][220/453]\tTrain Loss: 1.351\n",
      "Epoch [2][225/453]\tTrain Loss: 1.351\n",
      "Epoch [2][230/453]\tTrain Loss: 1.351\n",
      "Epoch [2][235/453]\tTrain Loss: 1.351\n",
      "Epoch [2][240/453]\tTrain Loss: 1.351\n",
      "Epoch [2][245/453]\tTrain Loss: 1.352\n",
      "Epoch [2][250/453]\tTrain Loss: 1.353\n",
      "Epoch [2][255/453]\tTrain Loss: 1.354\n",
      "Epoch [2][260/453]\tTrain Loss: 1.354\n",
      "Epoch [2][265/453]\tTrain Loss: 1.355\n",
      "Epoch [2][270/453]\tTrain Loss: 1.354\n",
      "Epoch [2][275/453]\tTrain Loss: 1.355\n",
      "Epoch [2][280/453]\tTrain Loss: 1.356\n",
      "Epoch [2][285/453]\tTrain Loss: 1.355\n",
      "Epoch [2][290/453]\tTrain Loss: 1.354\n",
      "Epoch [2][295/453]\tTrain Loss: 1.354\n",
      "Epoch [2][300/453]\tTrain Loss: 1.355\n",
      "Epoch [2][305/453]\tTrain Loss: 1.356\n",
      "Epoch [2][310/453]\tTrain Loss: 1.358\n",
      "Epoch [2][315/453]\tTrain Loss: 1.358\n",
      "Epoch [2][320/453]\tTrain Loss: 1.358\n",
      "Epoch [2][325/453]\tTrain Loss: 1.358\n",
      "Epoch [2][330/453]\tTrain Loss: 1.359\n",
      "Epoch [2][335/453]\tTrain Loss: 1.359\n",
      "Epoch [2][340/453]\tTrain Loss: 1.359\n",
      "Epoch [2][345/453]\tTrain Loss: 1.358\n",
      "Epoch [2][350/453]\tTrain Loss: 1.358\n",
      "Epoch [2][355/453]\tTrain Loss: 1.358\n",
      "Epoch [2][360/453]\tTrain Loss: 1.358\n",
      "Epoch [2][365/453]\tTrain Loss: 1.359\n",
      "Epoch [2][370/453]\tTrain Loss: 1.359\n",
      "Epoch [2][375/453]\tTrain Loss: 1.359\n",
      "Epoch [2][380/453]\tTrain Loss: 1.360\n",
      "Epoch [2][385/453]\tTrain Loss: 1.361\n",
      "Epoch [2][390/453]\tTrain Loss: 1.361\n",
      "Epoch [2][395/453]\tTrain Loss: 1.361\n",
      "Epoch [2][400/453]\tTrain Loss: 1.362\n",
      "Epoch [2][405/453]\tTrain Loss: 1.362\n",
      "Epoch [2][410/453]\tTrain Loss: 1.363\n",
      "Epoch [2][415/453]\tTrain Loss: 1.363\n",
      "Epoch [2][420/453]\tTrain Loss: 1.362\n",
      "Epoch [2][425/453]\tTrain Loss: 1.363\n",
      "Epoch [2][430/453]\tTrain Loss: 1.364\n",
      "Epoch [2][435/453]\tTrain Loss: 1.364\n",
      "Epoch [2][440/453]\tTrain Loss: 1.364\n",
      "Epoch [2][445/453]\tTrain Loss: 1.365\n",
      "Epoch [2][450/453]\tTrain Loss: 1.365\n",
      "Epoch [2][0/15]\t\t\tValid Loss: 1.531\n",
      "Epoch [2][5/15]\t\t\tValid Loss: 1.472\n",
      "Epoch [2][10/15]\t\t\tValid Loss: 1.513\n",
      "\n",
      "Candidate :▁Z wei ▁Mä n ner ▁in ▁Bad e anz ü gen ▁spring en ▁am ▁Strand ▁in ▁die ▁Lu ft .\n",
      "Candidate_labeled :  ['<start>', '▁Z', 'wei', '▁Mä', 'n', 'ner', '▁in', '▁Bad', 'e', 'anz', 'ü', 'gen', '▁spring', 'en', '▁am', '▁Strand', '▁in', '▁die', '▁Lu', 'ft', '.', '</s>']\n",
      "Real :▁Z wei ▁Mä n ner ▁in ▁Bad e ho sen ▁spring en ▁auf ▁eine m ▁m ä ß ig ▁be le b ten ▁Strand ▁in ▁die ▁Lu ft .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:08:58.930327 #######\n",
      "\n",
      "Epoch [3][0/453]\tTrain Loss: 1.284\n",
      "Epoch [3][5/453]\tTrain Loss: 1.237\n",
      "Epoch [3][10/453]\tTrain Loss: 1.230\n",
      "Epoch [3][15/453]\tTrain Loss: 1.248\n",
      "Epoch [3][20/453]\tTrain Loss: 1.250\n",
      "Epoch [3][25/453]\tTrain Loss: 1.263\n",
      "Epoch [3][30/453]\tTrain Loss: 1.267\n",
      "Epoch [3][35/453]\tTrain Loss: 1.271\n",
      "Epoch [3][40/453]\tTrain Loss: 1.272\n",
      "Epoch [3][45/453]\tTrain Loss: 1.271\n",
      "Epoch [3][50/453]\tTrain Loss: 1.270\n",
      "Epoch [3][55/453]\tTrain Loss: 1.271\n",
      "Epoch [3][60/453]\tTrain Loss: 1.267\n",
      "Epoch [3][65/453]\tTrain Loss: 1.275\n",
      "Epoch [3][70/453]\tTrain Loss: 1.275\n",
      "Epoch [3][75/453]\tTrain Loss: 1.280\n",
      "Epoch [3][80/453]\tTrain Loss: 1.283\n",
      "Epoch [3][85/453]\tTrain Loss: 1.280\n",
      "Epoch [3][90/453]\tTrain Loss: 1.281\n",
      "Epoch [3][95/453]\tTrain Loss: 1.281\n",
      "Epoch [3][100/453]\tTrain Loss: 1.281\n",
      "Epoch [3][105/453]\tTrain Loss: 1.284\n",
      "Epoch [3][110/453]\tTrain Loss: 1.288\n",
      "Epoch [3][115/453]\tTrain Loss: 1.291\n",
      "Epoch [3][120/453]\tTrain Loss: 1.293\n",
      "Epoch [3][125/453]\tTrain Loss: 1.293\n",
      "Epoch [3][130/453]\tTrain Loss: 1.292\n",
      "Epoch [3][135/453]\tTrain Loss: 1.292\n",
      "Epoch [3][140/453]\tTrain Loss: 1.294\n",
      "Epoch [3][145/453]\tTrain Loss: 1.295\n",
      "Epoch [3][150/453]\tTrain Loss: 1.297\n",
      "Epoch [3][155/453]\tTrain Loss: 1.296\n",
      "Epoch [3][160/453]\tTrain Loss: 1.296\n",
      "Epoch [3][165/453]\tTrain Loss: 1.296\n",
      "Epoch [3][170/453]\tTrain Loss: 1.297\n",
      "Epoch [3][175/453]\tTrain Loss: 1.299\n",
      "Epoch [3][180/453]\tTrain Loss: 1.300\n",
      "Epoch [3][185/453]\tTrain Loss: 1.301\n",
      "Epoch [3][190/453]\tTrain Loss: 1.303\n",
      "Epoch [3][195/453]\tTrain Loss: 1.305\n",
      "Epoch [3][200/453]\tTrain Loss: 1.305\n",
      "Epoch [3][205/453]\tTrain Loss: 1.307\n",
      "Epoch [3][210/453]\tTrain Loss: 1.307\n",
      "Epoch [3][215/453]\tTrain Loss: 1.308\n",
      "Epoch [3][220/453]\tTrain Loss: 1.309\n",
      "Epoch [3][225/453]\tTrain Loss: 1.309\n",
      "Epoch [3][230/453]\tTrain Loss: 1.308\n",
      "Epoch [3][235/453]\tTrain Loss: 1.309\n",
      "Epoch [3][240/453]\tTrain Loss: 1.308\n",
      "Epoch [3][245/453]\tTrain Loss: 1.308\n",
      "Epoch [3][250/453]\tTrain Loss: 1.309\n",
      "Epoch [3][255/453]\tTrain Loss: 1.310\n",
      "Epoch [3][260/453]\tTrain Loss: 1.310\n",
      "Epoch [3][265/453]\tTrain Loss: 1.311\n",
      "Epoch [3][270/453]\tTrain Loss: 1.311\n",
      "Epoch [3][275/453]\tTrain Loss: 1.311\n",
      "Epoch [3][280/453]\tTrain Loss: 1.312\n",
      "Epoch [3][285/453]\tTrain Loss: 1.312\n",
      "Epoch [3][290/453]\tTrain Loss: 1.315\n",
      "Epoch [3][295/453]\tTrain Loss: 1.315\n",
      "Epoch [3][300/453]\tTrain Loss: 1.315\n",
      "Epoch [3][305/453]\tTrain Loss: 1.317\n",
      "Epoch [3][310/453]\tTrain Loss: 1.318\n",
      "Epoch [3][315/453]\tTrain Loss: 1.317\n",
      "Epoch [3][320/453]\tTrain Loss: 1.318\n",
      "Epoch [3][325/453]\tTrain Loss: 1.319\n",
      "Epoch [3][330/453]\tTrain Loss: 1.318\n",
      "Epoch [3][335/453]\tTrain Loss: 1.319\n",
      "Epoch [3][340/453]\tTrain Loss: 1.319\n",
      "Epoch [3][345/453]\tTrain Loss: 1.320\n",
      "Epoch [3][350/453]\tTrain Loss: 1.319\n",
      "Epoch [3][355/453]\tTrain Loss: 1.319\n",
      "Epoch [3][360/453]\tTrain Loss: 1.319\n",
      "Epoch [3][365/453]\tTrain Loss: 1.319\n",
      "Epoch [3][370/453]\tTrain Loss: 1.320\n",
      "Epoch [3][375/453]\tTrain Loss: 1.320\n",
      "Epoch [3][380/453]\tTrain Loss: 1.319\n",
      "Epoch [3][385/453]\tTrain Loss: 1.321\n",
      "Epoch [3][390/453]\tTrain Loss: 1.322\n",
      "Epoch [3][395/453]\tTrain Loss: 1.323\n",
      "Epoch [3][400/453]\tTrain Loss: 1.323\n",
      "Epoch [3][405/453]\tTrain Loss: 1.323\n",
      "Epoch [3][410/453]\tTrain Loss: 1.323\n",
      "Epoch [3][415/453]\tTrain Loss: 1.324\n",
      "Epoch [3][420/453]\tTrain Loss: 1.324\n",
      "Epoch [3][425/453]\tTrain Loss: 1.323\n",
      "Epoch [3][430/453]\tTrain Loss: 1.325\n",
      "Epoch [3][435/453]\tTrain Loss: 1.325\n",
      "Epoch [3][440/453]\tTrain Loss: 1.326\n",
      "Epoch [3][445/453]\tTrain Loss: 1.326\n",
      "Epoch [3][450/453]\tTrain Loss: 1.327\n",
      "Epoch [3][0/15]\t\t\tValid Loss: 1.385\n",
      "Epoch [3][5/15]\t\t\tValid Loss: 1.486\n",
      "Epoch [3][10/15]\t\t\tValid Loss: 1.504\n",
      "\n",
      "Candidate :▁Z wei ▁Mä n ner ▁in ▁sch war zen ▁Kle ider n ▁in ▁ein er ▁Stadt .\n",
      "Candidate_labeled :  ['<start>', '▁Z', 'wei', '▁Mä', 'n', 'ner', '▁in', '▁sch', 'war', 'zen', '▁Kle', 'ider', 'n', '▁in', '▁ein', 'er', '▁Stadt', '.', '</s>']\n",
      "Real :▁Z wei ▁Mä n ner ▁in ▁Schwarz ▁in ▁ein er ▁Stadt\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:08:59.777595 #######\n",
      "\n",
      "Epoch [4][0/453]\tTrain Loss: 1.248\n",
      "Epoch [4][5/453]\tTrain Loss: 1.272\n",
      "Epoch [4][10/453]\tTrain Loss: 1.262\n",
      "Epoch [4][15/453]\tTrain Loss: 1.272\n",
      "Epoch [4][20/453]\tTrain Loss: 1.279\n",
      "Epoch [4][25/453]\tTrain Loss: 1.266\n",
      "Epoch [4][30/453]\tTrain Loss: 1.260\n",
      "Epoch [4][35/453]\tTrain Loss: 1.259\n",
      "Epoch [4][40/453]\tTrain Loss: 1.262\n",
      "Epoch [4][45/453]\tTrain Loss: 1.262\n",
      "Epoch [4][50/453]\tTrain Loss: 1.254\n",
      "Epoch [4][55/453]\tTrain Loss: 1.254\n",
      "Epoch [4][60/453]\tTrain Loss: 1.253\n",
      "Epoch [4][65/453]\tTrain Loss: 1.250\n",
      "Epoch [4][70/453]\tTrain Loss: 1.249\n",
      "Epoch [4][75/453]\tTrain Loss: 1.250\n",
      "Epoch [4][80/453]\tTrain Loss: 1.255\n",
      "Epoch [4][85/453]\tTrain Loss: 1.252\n",
      "Epoch [4][90/453]\tTrain Loss: 1.250\n",
      "Epoch [4][95/453]\tTrain Loss: 1.251\n",
      "Epoch [4][100/453]\tTrain Loss: 1.256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      6\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \n\u001b[1;32m----> 7\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: transformer_optimizer}\n\u001b[0;32m     10\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(state, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_new\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth.tar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[35], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, transformer, criterion, epoch)\u001b[0m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, output_target, output_target_mask)\n\u001b[0;32m     21\u001b[0m transformer_optimizer\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m transformer_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     25\u001b[0m sum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m samples\n",
      "File \u001b[1;32md:\\anaconda\\envs\\Pray\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\Pray\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        \n",
    "    start_time = datetime.now() \n",
    "    train(train_loader, transformer, criterion, epoch)\n",
    "    \n",
    "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    torch.save(state, 'checkpoint_new' + str(epoch+20) + '.pth.tar')\n",
    "    \n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print('#######   Time elapsed (hh:mm:ss.ms) {} #######'.format(time_elapsed))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "# 저장된 파일을 불러올 때\n",
    "checkpoint = torch.load('checkpoint_new23.pth.tar')\n",
    "\n",
    "# 불러온 checkpoint에서 모델 상태나 다른 필요한 요소들을 추출할 수 있습니다.\n",
    "transformer = deepcopy(checkpoint['transformer'])\n",
    "\n",
    "# 모델을 evaluation 모드로 설정 (필요에 따라)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = {v:k for k,v in tokenizer.get_vocab().items()} \n",
    "bb[58101] = '<start>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 128]), torch.Size([64, 128]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))[0].shape, next(iter(test_loader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   93,   175,     5,  ..., 58100, 58100, 58100],\n",
       "        [   93, 13835, 21368,  ..., 58100, 58100, 58100],\n",
       "        [   93,  4040,     5,  ..., 58100, 58100, 58100],\n",
       "        ...,\n",
       "        [ 2358,   734,    48,  ..., 58100, 58100, 58100],\n",
       "        [  282,  6060,   175,  ..., 58100, 58100, 58100],\n",
       "        [   93,  4040,    67,  ..., 58100, 58100, 58100]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:17<28:59,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3972977617472836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1000 [00:34<27:21,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3077524478751904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1000 [00:52<31:23,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3299985023676016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 40/1000 [01:08<26:52,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3424956239810124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/1000 [01:23<23:48,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3496635901763184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 60/1000 [01:40<27:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3477268563532785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 70/1000 [01:58<24:06,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3405755491416081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 80/1000 [02:15<29:22,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.33876084907308224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 90/1000 [02:33<31:07,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.33864606430720645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [02:51<28:58,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3337108175544898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 110/1000 [03:07<24:24,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3308155217487101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 120/1000 [03:23<21:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3305355339547221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 130/1000 [03:36<21:14,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3277446525082295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 140/1000 [03:52<21:24,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3245753749507594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 150/1000 [04:11<25:45,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3305214710270147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 160/1000 [04:27<22:07,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3306757317347729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 170/1000 [04:44<22:31,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3357128571619224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 180/1000 [05:00<22:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34421669357851997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 190/1000 [05:16<21:48,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34200811359222777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [05:33<24:20,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3423341133461381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 210/1000 [05:50<23:49,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34602861610634233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 220/1000 [06:05<20:58,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34373244329757124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 230/1000 [06:22<22:24,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3436402076568826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 240/1000 [06:40<21:49,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.342276682622346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 250/1000 [06:57<20:55,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3405453475793308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 260/1000 [07:14<19:57,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.33985943517549877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 270/1000 [07:32<27:07,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3448753942120355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 280/1000 [07:51<21:30,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34826665586438477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 290/1000 [08:06<17:50,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35174698554960765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [08:21<17:30,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3527599872490309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 310/1000 [08:39<22:54,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3500456506031758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 320/1000 [08:58<17:47,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3504514059427123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 330/1000 [09:14<16:08,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3515879039624161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 340/1000 [09:32<16:10,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34821355501933604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 350/1000 [09:52<21:50,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3478043613985935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 360/1000 [10:10<19:13,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3486124243884541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 370/1000 [10:28<20:32,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3494201129986728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 380/1000 [10:48<24:21,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34647476148148976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 390/1000 [11:06<17:58,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3435768600019465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/1000 [11:23<14:07,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.345605544774616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 410/1000 [11:40<17:33,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3445902648008178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 420/1000 [11:57<15:51,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34642679297150414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 430/1000 [12:17<20:18,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34513623321652354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 440/1000 [12:36<18:32,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3477885684117134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 450/1000 [12:53<17:24,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3502066429228246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 460/1000 [13:10<16:44,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3525536428189053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 470/1000 [13:26<13:22,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35071318476964775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 480/1000 [13:43<15:26,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3517505230577197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 490/1000 [13:59<13:15,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35112426694410614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/1000 [14:16<15:03,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3518546159160246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 510/1000 [14:33<18:41,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3506893775773984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 520/1000 [14:47<11:39,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3509191273373832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 530/1000 [15:04<13:38,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.352084461438211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 540/1000 [15:25<18:57,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35038608868336557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 550/1000 [15:42<12:26,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3509250279815551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 560/1000 [15:58<12:02,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3529906837422662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 570/1000 [16:18<14:08,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35220636413205486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 580/1000 [16:34<12:13,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3522836038643244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 590/1000 [16:51<11:48,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35131230095675975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 600/1000 [17:08<12:05,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3531890215207289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 610/1000 [17:27<11:07,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35331303289960364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 620/1000 [17:46<12:40,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3532256775638248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 630/1000 [18:06<12:56,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3516632590952345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 640/1000 [18:24<10:52,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35158769954709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 650/1000 [18:44<11:02,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3500273878924654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 660/1000 [19:03<09:55,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34964479122656833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 670/1000 [19:20<10:24,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3515148117366053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 680/1000 [19:40<11:33,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35027415702698567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 690/1000 [20:01<09:19,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34895182275511283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 700/1000 [20:20<10:48,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34756092096335395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 710/1000 [20:38<09:13,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34747778050569267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 720/1000 [20:55<06:34,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34841461726939355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 730/1000 [21:12<08:37,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34877053358750065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 740/1000 [21:29<07:40,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.346996876064863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 750/1000 [21:49<08:46,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3473672361284632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 760/1000 [22:06<06:53,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3479083718594225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 770/1000 [22:25<08:17,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34630307797342724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 780/1000 [22:42<06:19,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3487236668965047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 790/1000 [23:04<07:51,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34769799386475186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/1000 [23:21<05:40,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34781251199225954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 810/1000 [23:39<05:29,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3473315547589149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 820/1000 [23:59<05:16,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3484494180454765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 830/1000 [24:20<07:01,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3485686720539806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 840/1000 [24:40<05:58,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3487054756269906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 850/1000 [24:59<05:37,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34934174126064865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 860/1000 [25:14<03:26,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3515561674974034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 870/1000 [25:33<04:32,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3518512128277992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 880/1000 [25:53<03:49,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3511139052801695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 890/1000 [26:19<04:38,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.35147962438347685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [26:40<03:26,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3505446968151889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 910/1000 [27:01<03:48,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34954335518693097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 920/1000 [27:20<02:55,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34958911891527567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 930/1000 [27:42<02:41,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34842576993128316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 940/1000 [28:00<01:47,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34679061993870525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 950/1000 [28:17<01:21,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34789597239182035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 960/1000 [28:40<01:52,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3475617186309749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 970/1000 [29:01<01:11,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3472591574948545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 980/1000 [29:23<00:51,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.3458723620371342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 990/1000 [29:45<00:22,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34540253252336567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [30:04<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU -4 score :  0.34443188787549256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "candidate = []\n",
    "real = []\n",
    "\n",
    "max_len = 128\n",
    "\n",
    "for a,b in zip(tqdm(test_en),test_ge):\n",
    "    enc_qus = a\n",
    "    real_qus = b\n",
    "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "    \n",
    "    question.to(device)\n",
    "    real_qus.to(device)\n",
    "    transformer.to(device)\n",
    "    \n",
    "    question_mask = (question!=58100).to(device).unsqueeze(1).unsqueeze(1)\n",
    "    sentence = beam_search(transformer, question, question_mask, int(max_len), dict)\n",
    "    \n",
    "    c = [bb[i] for i in sentence if (i != 0) and (i != 58100) and (i != 58101)]\n",
    "    r = [bb[i.tolist()] for i in real_qus if (i.tolist() != 0) and (i.tolist() != 58100)  and (i != 58101)]\n",
    "    \n",
    "    candidate.append(c)\n",
    "    real.append(r)\n",
    "    \n",
    "    data = 0\n",
    "    \n",
    "    for i,j in zip(real,candidate):\n",
    "        data += bleu.sentence_bleu([i],j,weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method1)\n",
    "        \n",
    "        \n",
    "    if len(real) % 10  == 0:\n",
    "        print('BLEU -4 score : ', data / len(real))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BLEU -4 score :  0.34443188787549256\n"
     ]
    }
   ],
   "source": [
    "print('Final BLEU -4 score : ', data / len(real))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
