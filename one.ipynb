{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bentrevett/multi30k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\Pray\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset.map(lambda e: tokenizer(e['en'], padding= False), batched=True)\n",
    "dataset3 = dataset.map(lambda e: tokenizer(e['de'], padding= False), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58101 # 이를 start token으로 지정.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique([len(i) for i in dataset2['train']['input_ids']]), np.unique([len(i) for i in dataset3['train']['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences_en(sequences):\n",
    "    max_len = 128\n",
    "    padded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) >= max_len:\n",
    "            padded_sequence = sequence[:max_len]  # 최대 길이까지 잘라냄\n",
    "        else:\n",
    "            padded_sequence = sequence + [58100] * (max_len - len(sequence))  # 패딩 추가\n",
    "        padded_sequences.append(padded_sequence)\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences_de(sequences):\n",
    "    max_len = 128\n",
    "    padded_sequences = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) >= max_len:\n",
    "            padded_sequence = [58101] + sequence[:max_len-1]  # 최대 길이까지 잘라냄\n",
    "        else:\n",
    "            padded_sequence = [58101] + sequence + [58100] * (max_len - len(sequence) - 1)  # 패딩 추가\n",
    "        padded_sequences.append(padded_sequence)\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_batch = pad_sequences(dataset2['train']['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en, train_ge = torch.tensor(pad_sequences_en(dataset2['train']['input_ids'])), torch.tensor(pad_sequences_de(dataset3['train']['input_ids']))\n",
    "valid_en, valid_ge = torch.tensor(pad_sequences_en(dataset2['validation']['input_ids'])), torch.tensor(pad_sequences_de(dataset3['validation']['input_ids']))\n",
    "test_en, test_ge = torch.tensor(pad_sequences_en(dataset2['test']['input_ids'])), torch.tensor(pad_sequences_de(dataset3['test']['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58101,   589,  7554,  7861, 22012,    95,   197,  5192,    18, 17694,\n",
       "           34,   731,  7199,    82,    49,  4407,    15,     5,     9,   394,\n",
       "         1258,  1578,  5154,   526,    45, 14243,  3351,     3,     0, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ge[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({128}, {128})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([len(i) for i in train_en]), set([len(i) for i in train_ge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, inputs, output):\n",
    "\n",
    "        self.inputs = inputs\n",
    "        self.output = output\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        inputs = self.inputs[idx]\n",
    "        output = self.output[idx]\n",
    "        \n",
    "        return inputs, output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_en, train_ge)\n",
    "valid_dataset = Dataset(valid_en, valid_ge)\n",
    "test_dataset = Dataset(test_en, test_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = False, drop_last = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 64, shuffle = False, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, max_len = 128):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.embed = nn.Embedding(vocab_size + 1, d_model)\n",
    "        self.pe = self.create_positinal_encoding(max_len, self.d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def create_positinal_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        for pos in range(max_len):  \n",
    "            for i in range(0, d_model, 2):  \n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)  \n",
    "        return pe\n",
    "\n",
    "    def forward(self, encoded_words):\n",
    "        \n",
    "        embedding = self.embed(encoded_words) * torch.sqrt(torch.tensor(self.d_model)).to(device)\n",
    "        embedding += self.pe[:, :embedding.size(1)]   \n",
    "        embedding = self.dropout(embedding)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attention(nn.Module):\n",
    "    \n",
    "#     def __init__(self, embedding_size = 512):\n",
    "        \n",
    "#         self.data = data\n",
    "#         self.embedding_size= embedding_size\n",
    "#         self.weight_Q = nn.Linear(embedding_size, embedding_size)\n",
    "#         self.weight_K = nn.Linear(embedding_size, embedding_size)\n",
    "#         self.weight_V = nn.Linear(embedding_size, embedding_size)\n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "#     def forward(self, data):\n",
    "        \n",
    "#         Q = self.weight_Q(data)\n",
    "#         K = self.weight_K(data)\n",
    "#         V = self.weight_V(data)\n",
    "#         score = torch.matmul(Q,K.T) / torch.sqrt(self.embedding_size)\n",
    "#         value = self.softmax(score) * V\n",
    "#         return value\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inputs, outputs_input, outputs_target):\n",
    "    \n",
    "    def subsequent_mask(size):\n",
    "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype = torch.uint8)\n",
    "        return mask.unsqueeze(0) # 상삼각행렬 생성 -> 행과 열을 뒤 바꾸어 하삼각행렬로 바꿈. (밑에가 다 0)\n",
    "    \n",
    "    inputs_mask = inputs != 58100\n",
    "    inputs_mask = inputs_mask.to(device)\n",
    "    inputs_mask = inputs_mask.unsqueeze(1).unsqueeze(1) # 각  input에 대해서 상삼각행렬에 대응하도록 설정.\n",
    "    \n",
    "    outputs_input_mask = outputs_input != 58100\n",
    "    outputs_input_mask = outputs_input_mask.unsqueeze(1) \n",
    "    outputs_input_mask = outputs_input_mask & subsequent_mask(outputs_input.size(-1)).type_as(outputs_input_mask.data)\n",
    "    outputs_input_mask = outputs_input_mask.unsqueeze(1)\n",
    "    # masking을 해줌으로서, \n",
    "\n",
    "    \n",
    "    outputs_target_mask = outputs_target != 58100\n",
    "    \n",
    "    return inputs_mask, outputs_input_mask, outputs_target_mask\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4386,  1296,     2,  ..., 58100, 58100, 58100],\n",
       "        [15036,  1135,     5,  ..., 58100, 58100, 58100],\n",
       "        [   93,   839,  4040,  ..., 58100, 58100, 58100],\n",
       "        ...,\n",
       "        [ 4386,  8722,  2013,  ..., 58100, 58100, 58100],\n",
       "        [  282, 17525,   175,  ..., 58100, 58100, 58100],\n",
       "        [   93,   175,     5,  ..., 58100, 58100, 58100]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key  = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.concat = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, query, key, value, mask):\n",
    "        \n",
    "        query = self.query(query)\n",
    "        key = self.key(key)\n",
    "        value = self.value(value)\n",
    "        \n",
    "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        \n",
    "\n",
    "        scores = torch.matmul(query, key.permute(0 ,1 ,3, 2)) / math.sqrt(query.size(-1))\n",
    "        \n",
    "        # print(query.shape, key.shape, value.shape, mask.shape, scores.shape)\n",
    "\n",
    "        \n",
    "        scores = scores.masked_fill(mask == 0, -1e9) # masking 된 것에 매우 작은 수 부여 -> softmax 계산시 -inf 로 계산되어짐.\n",
    "        weights = F.softmax(scores, dim = -1) # attention score 계산\n",
    "        context = torch.matmul(weights, value)  # attention value 계산\n",
    "        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
    "        \n",
    "        interacted = self.concat(context)\n",
    "        \n",
    "        return interacted\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, middle_dim = 2048):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, embeddings, mask):\n",
    "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
    "        interacted = self.layernorm(interacted + embeddings)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        encoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return encoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.src_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
    "        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n",
    "        query = self.layernorm(query + embeddings)\n",
    "        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n",
    "        interacted = self.layernorm(interacted + query)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        decoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P_Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, vocab_size):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size + 1\n",
    "        self.embed = Embeddings(self.vocab_size, d_model)\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_words, src_mask):\n",
    "        src_embeddings = self.embed(src_words)\n",
    "        encoded_layers = []\n",
    "        for layer in self.encoder:\n",
    "            src_embeddings = layer(src_embeddings, src_mask)\n",
    "            encoded_layers.append(src_embeddings)\n",
    "            \n",
    "        return encoded_layers\n",
    "\n",
    "    def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
    "        tgt_embeddings = self.embed(target_words)\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            tgt_embeddings = layer(tgt_embeddings, src_embeddings[i], src_mask, target_mask)\n",
    "            decoded_layers.append(tgt_embeddings)\n",
    "        return tgt_embeddings\n",
    "\n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded_layers = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded_layers, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, vocab_size):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size + 1\n",
    "        self.embed = Embeddings(self.vocab_size, d_model)\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_words, src_mask):\n",
    "        src_embeddings = self.embed(src_words)\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            src_embeddings = layer(src_embeddings, src_mask)\n",
    "            \n",
    "        return src_embeddings\n",
    "\n",
    "    def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
    "        tgt_embeddings = self.embed(target_words)\n",
    "        for layer in self.decoder:\n",
    "            tgt_embeddings = layer(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
    "        return tgt_embeddings\n",
    "\n",
    "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
    "        encoded = self.encode(src_words, src_mask)\n",
    "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
    "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
    "        return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamWarmup:\n",
    "    \n",
    "    def __init__(self, model_size, warmup_steps, optimizer):\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        self.current_step = 0\n",
    "        self.lr = 0\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        self.current_step += 1\n",
    "        lr = self.get_lr()\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "        self.lr = lr\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LossWithLS(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, smooth):\n",
    "        super(LossWithLS, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, prediction, target, mask):\n",
    "        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n",
    "        target = target.contiguous().view(-1)   # (batch_size * max_words)\n",
    "        mask = mask.float()\n",
    "        mask = mask.view(-1)       # (batch_size * max_words)\n",
    "        \n",
    "        # Smoothed one-hot labels\n",
    "        labels = torch.full_like(prediction, self.smooth / (self.size - 1))\n",
    "        labels.scatter_(1, target.unsqueeze(1), 1 - self.smooth)\n",
    "        \n",
    "        # Apply mask\n",
    "        masked_prediction = prediction * mask.unsqueeze(1)\n",
    "        masked_labels = labels * mask.unsqueeze(1)\n",
    "\n",
    "        \n",
    "        # Calculate negative log likelihood loss\n",
    "        loss = F.nll_loss(masked_prediction, target, reduction='none')\n",
    "        loss *= mask\n",
    "        \n",
    "        # Normalize the loss\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "heads = 8\n",
    "num_layers = 6\n",
    "num_layers = 6\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "vocab_len = len(tokenizer.get_vocab())\n",
    "\n",
    "transformer = Transformer(d_model = d_model , heads = heads, num_layers = num_layers, vocab_size = vocab_len)\n",
    "transformer = transformer.to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters())\n",
    "transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(vocab_len, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader.dataset))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoon303b\u001b[0m (\u001b[33mku_software\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\USER\\Documents\\Jupyter_Notebook\\Graduate_중앙대\\Second\\wandb\\run-20240426_113635-g3rn74y9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ku_software/Transformer_Hard_Coding/runs/g3rn74y9' target=\"_blank\">earthy-dream-27</a></strong> to <a href='https://wandb.ai/ku_software/Transformer_Hard_Coding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ku_software/Transformer_Hard_Coding' target=\"_blank\">https://wandb.ai/ku_software/Transformer_Hard_Coding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ku_software/Transformer_Hard_Coding/runs/g3rn74y9' target=\"_blank\">https://wandb.ai/ku_software/Transformer_Hard_Coding/runs/g3rn74y9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ku_software/Transformer_Hard_Coding/runs/g3rn74y9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ccfdc0b650>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Transformer_Hard_Coding\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"loss\": 'KLDivergence',\n",
    "    \"architecture\": \"Transformer\",\n",
    "    \"optimizer\" : 'AdamWarmup',\n",
    "    'layer' : 6,\n",
    "    'heads' : 8,\n",
    "    'd_model' : 64   \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def generate_next_words(transformer, sequence, encoded, question_mask, beam_width):\n",
    "    \n",
    "    start_token = 58101\n",
    "    \n",
    "    if not sequence:\n",
    "        return [(start_token, 0)]\n",
    "    \n",
    "    size = len(sequence)\n",
    "    target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "    target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    words = torch.LongTensor([sequence]).to(device)\n",
    "\n",
    "    decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
    "    predictions = transformer.logit(decoded[:, -1])\n",
    "\n",
    "    # Apply log_softmax\n",
    "    log_probs = F.log_softmax(predictions, dim = -1)\n",
    "\n",
    "    # Get top-k words\n",
    "    top_k_probs, top_k_indices = torch.topk(log_probs, beam_width, dim=-1)\n",
    "    top_k_probs = top_k_probs.squeeze().tolist()\n",
    "    top_k_indices = top_k_indices.squeeze().tolist()\n",
    "\n",
    "    next_words = [(word, prob) for word, prob in zip(top_k_indices, top_k_probs)]\n",
    "    return next_words\n",
    "\n",
    "\n",
    "def beam_search(transformer, question, question_mask, max_len, dict, beam_width=5):\n",
    "    transformer.eval()\n",
    "    start_token = 58101\n",
    "    end_token = 0\n",
    "\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "\n",
    "    beams = [([], 0)] \n",
    "\n",
    "    for step in range(max_len):\n",
    "        candidates = []\n",
    "\n",
    "        for seq, score in beams:\n",
    "            if seq and seq[-1] == end_token:\n",
    "                candidates.append((seq, score))\n",
    "                continue\n",
    "            \n",
    "            next_words = generate_next_words(transformer, seq, encoded, question_mask, beam_width)\n",
    "\n",
    "            for word, log_prob in next_words:\n",
    "                candidates.append((seq + [word], score + log_prob))\n",
    "\n",
    "        # Select top-k candidates\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        beams = candidates[:beam_width]\n",
    "\n",
    "        # Check if all beams have ended\n",
    "        if all(seq[-1] == end_token for seq, _ in beams):\n",
    "            break\n",
    "\n",
    "    best_seq, _ = max(beams, key=lambda x: x[1])\n",
    "    return best_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = {v:k for k,v in tokenizer.get_vocab().items()} \n",
    "bb[58101] = '<start>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, transformer, criterion, epoch):\n",
    "    \n",
    "    transformer.train()\n",
    "    sum_loss, valid_sum_loss = 0, 0\n",
    "    count, valid_count = 0, 0\n",
    "    \n",
    "    for i, (inputs, output) in enumerate(train_loader):\n",
    "        \n",
    "        samples = inputs.shape[0]\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        output = output.to(device)\n",
    "        \n",
    "        output_in = output[:,:-1]\n",
    "        output_target = output[:,1:]\n",
    "        inputs_mask, output_in_mask, output_target_mask = create_masks(inputs, output_in, output_target)\n",
    "        \n",
    "        out = transformer(inputs, inputs_mask, output_in, output_in_mask)\n",
    "        \n",
    "        loss = criterion(out, output_target, output_target_mask)\n",
    "        transformer_optimizer.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        transformer_optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item() * samples\n",
    "        count += samples\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(\"Epoch [{}][{}/{}]\\tTrain Loss: {:.3f}\".format(epoch, i, len(train_loader), sum_loss/count))\n",
    "            wandb.log({\"Training loss\" : sum_loss/count})\n",
    "    \n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, output) in enumerate(valid_loader):\n",
    "            \n",
    "            samples = inputs.shape[0]\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            output = output.to(device)\n",
    "            \n",
    "            output_in = output[:,:-1]\n",
    "            output_target = output[:,1:]\n",
    "            \n",
    "            inputs_mask, output_in_mask, output_target_mask = create_masks(inputs, output_in, output_target)\n",
    "            out = transformer(inputs, inputs_mask, output_in, output_in_mask)\n",
    "            \n",
    "            loss = criterion(out, output_target, output_target_mask)\n",
    "            \n",
    "            valid_sum_loss += loss.item() * samples\n",
    "            valid_count += samples\n",
    "        \n",
    "            if i % 5   == 0:\n",
    "                print(\"Epoch [{}][{}/{}]\\t\\t\\tValid Loss: {:.3f}\".format(epoch, i, len(valid_loader), valid_sum_loss/valid_count))\n",
    "                wandb.log({\"Validation loss\" :  valid_sum_loss/valid_count })\n",
    "                \n",
    "\n",
    "    max_len = 128\n",
    "    A = random.randint(1, 64)\n",
    "    B = next(iter(test_loader))\n",
    "    \n",
    "    enc_qus = B[0][A]\n",
    "    real_qus = B[1][A]\n",
    "    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "    question_mask = (question!=58100).to(device).unsqueeze(1).unsqueeze(1)\n",
    "    sentence = beam_search(transformer, question, question_mask, int(max_len), dict)\n",
    "    \n",
    "    candidate = [bb[i] for i in sentence if (i != 0) and (i != 58100) and (i != 58101)]\n",
    "    real = [bb[i.tolist()] for i in real_qus if (i.tolist() != 0) and (i.tolist() != 58100)  and (i != 58101)]\n",
    "    print()\n",
    "    print('Candidate :'  + ' '.join(candidate))\n",
    "    print('Candidate_labeled : ', [bb[i] for i in sentence])\n",
    "    print('Real :' + ' '.join(real))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 724.0773, 1448.1547, 1448.1547])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor((64, 128, 128)) * math.sqrt(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_en, train_ge)\n",
    "valid_dataset = Dataset(valid_en, valid_ge)\n",
    "test_dataset = Dataset(test_en, test_ge)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True, drop_last = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 64, shuffle = True, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random.randint(1, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0][0/453]\tTrain Loss: 2.834\n",
      "Epoch [0][5/453]\tTrain Loss: 2.886\n",
      "Epoch [0][10/453]\tTrain Loss: 2.854\n",
      "Epoch [0][15/453]\tTrain Loss: 2.859\n",
      "Epoch [0][20/453]\tTrain Loss: 2.857\n",
      "Epoch [0][25/453]\tTrain Loss: 2.849\n",
      "Epoch [0][30/453]\tTrain Loss: 2.839\n",
      "Epoch [0][35/453]\tTrain Loss: 2.838\n",
      "Epoch [0][40/453]\tTrain Loss: 2.843\n",
      "Epoch [0][45/453]\tTrain Loss: 2.841\n",
      "Epoch [0][50/453]\tTrain Loss: 2.837\n",
      "Epoch [0][55/453]\tTrain Loss: 2.837\n",
      "Epoch [0][60/453]\tTrain Loss: 2.833\n",
      "Epoch [0][65/453]\tTrain Loss: 2.828\n",
      "Epoch [0][70/453]\tTrain Loss: 2.825\n",
      "Epoch [0][75/453]\tTrain Loss: 2.822\n",
      "Epoch [0][80/453]\tTrain Loss: 2.825\n",
      "Epoch [0][85/453]\tTrain Loss: 2.818\n",
      "Epoch [0][90/453]\tTrain Loss: 2.813\n",
      "Epoch [0][95/453]\tTrain Loss: 2.811\n",
      "Epoch [0][100/453]\tTrain Loss: 2.810\n",
      "Epoch [0][105/453]\tTrain Loss: 2.805\n",
      "Epoch [0][110/453]\tTrain Loss: 2.800\n",
      "Epoch [0][115/453]\tTrain Loss: 2.798\n",
      "Epoch [0][120/453]\tTrain Loss: 2.795\n",
      "Epoch [0][125/453]\tTrain Loss: 2.794\n",
      "Epoch [0][130/453]\tTrain Loss: 2.788\n",
      "Epoch [0][135/453]\tTrain Loss: 2.789\n",
      "Epoch [0][140/453]\tTrain Loss: 2.789\n",
      "Epoch [0][145/453]\tTrain Loss: 2.783\n",
      "Epoch [0][150/453]\tTrain Loss: 2.781\n",
      "Epoch [0][155/453]\tTrain Loss: 2.780\n",
      "Epoch [0][160/453]\tTrain Loss: 2.775\n",
      "Epoch [0][165/453]\tTrain Loss: 2.773\n",
      "Epoch [0][170/453]\tTrain Loss: 2.774\n",
      "Epoch [0][175/453]\tTrain Loss: 2.774\n",
      "Epoch [0][180/453]\tTrain Loss: 2.772\n",
      "Epoch [0][185/453]\tTrain Loss: 2.769\n",
      "Epoch [0][190/453]\tTrain Loss: 2.768\n",
      "Epoch [0][195/453]\tTrain Loss: 2.766\n",
      "Epoch [0][200/453]\tTrain Loss: 2.762\n",
      "Epoch [0][205/453]\tTrain Loss: 2.760\n",
      "Epoch [0][210/453]\tTrain Loss: 2.758\n",
      "Epoch [0][215/453]\tTrain Loss: 2.756\n",
      "Epoch [0][220/453]\tTrain Loss: 2.756\n",
      "Epoch [0][225/453]\tTrain Loss: 2.752\n",
      "Epoch [0][230/453]\tTrain Loss: 2.750\n",
      "Epoch [0][235/453]\tTrain Loss: 2.750\n",
      "Epoch [0][240/453]\tTrain Loss: 2.748\n",
      "Epoch [0][245/453]\tTrain Loss: 2.747\n",
      "Epoch [0][250/453]\tTrain Loss: 2.744\n",
      "Epoch [0][255/453]\tTrain Loss: 2.744\n",
      "Epoch [0][260/453]\tTrain Loss: 2.744\n",
      "Epoch [0][265/453]\tTrain Loss: 2.741\n",
      "Epoch [0][270/453]\tTrain Loss: 2.738\n",
      "Epoch [0][275/453]\tTrain Loss: 2.736\n",
      "Epoch [0][280/453]\tTrain Loss: 2.734\n",
      "Epoch [0][285/453]\tTrain Loss: 2.731\n",
      "Epoch [0][290/453]\tTrain Loss: 2.730\n",
      "Epoch [0][295/453]\tTrain Loss: 2.728\n",
      "Epoch [0][300/453]\tTrain Loss: 2.727\n",
      "Epoch [0][305/453]\tTrain Loss: 2.724\n",
      "Epoch [0][310/453]\tTrain Loss: 2.723\n",
      "Epoch [0][315/453]\tTrain Loss: 2.722\n",
      "Epoch [0][320/453]\tTrain Loss: 2.721\n",
      "Epoch [0][325/453]\tTrain Loss: 2.719\n",
      "Epoch [0][330/453]\tTrain Loss: 2.717\n",
      "Epoch [0][335/453]\tTrain Loss: 2.715\n",
      "Epoch [0][340/453]\tTrain Loss: 2.712\n",
      "Epoch [0][345/453]\tTrain Loss: 2.710\n",
      "Epoch [0][350/453]\tTrain Loss: 2.709\n",
      "Epoch [0][355/453]\tTrain Loss: 2.706\n",
      "Epoch [0][360/453]\tTrain Loss: 2.705\n",
      "Epoch [0][365/453]\tTrain Loss: 2.704\n",
      "Epoch [0][370/453]\tTrain Loss: 2.702\n",
      "Epoch [0][375/453]\tTrain Loss: 2.700\n",
      "Epoch [0][380/453]\tTrain Loss: 2.699\n",
      "Epoch [0][385/453]\tTrain Loss: 2.697\n",
      "Epoch [0][390/453]\tTrain Loss: 2.694\n",
      "Epoch [0][395/453]\tTrain Loss: 2.693\n",
      "Epoch [0][400/453]\tTrain Loss: 2.693\n",
      "Epoch [0][405/453]\tTrain Loss: 2.691\n",
      "Epoch [0][410/453]\tTrain Loss: 2.688\n",
      "Epoch [0][415/453]\tTrain Loss: 2.685\n",
      "Epoch [0][420/453]\tTrain Loss: 2.684\n",
      "Epoch [0][425/453]\tTrain Loss: 2.682\n",
      "Epoch [0][430/453]\tTrain Loss: 2.681\n",
      "Epoch [0][435/453]\tTrain Loss: 2.681\n",
      "Epoch [0][440/453]\tTrain Loss: 2.679\n",
      "Epoch [0][445/453]\tTrain Loss: 2.678\n",
      "Epoch [0][450/453]\tTrain Loss: 2.676\n",
      "Epoch [0][0/15]\t\t\tValid Loss: 2.465\n",
      "Epoch [0][5/15]\t\t\tValid Loss: 2.397\n",
      "Epoch [0][10/15]\t\t\tValid Loss: 2.464\n",
      "\n",
      "Candidate :▁Mä n ner ▁ spiel en ▁in ▁der ▁N ä he ▁eine s ▁Ball ▁in ▁der ▁Lu ft .\n",
      "Candidate_labeled :  ['<start>', '▁Mä', 'n', 'ner', '▁', 'spiel', 'en', '▁in', '▁der', '▁N', 'ä', 'he', '▁eine', 's', '▁Ball', '▁in', '▁der', '▁Lu', 'ft', '.', '</s>']\n",
      "Real :▁Mä n ner , ▁die ▁Vol ley ball ▁ spiel en , ▁wo bei ▁ein ▁Mann ▁den ▁Ball ▁nicht ▁tri ff t , ▁w ä hren d ▁se ine ▁Hä nde ▁ immer ▁no ch ▁in ▁der ▁Lu ft ▁sin d .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:09:29.694125 #######\n",
      "\n",
      "Epoch [1][0/453]\tTrain Loss: 2.437\n",
      "Epoch [1][5/453]\tTrain Loss: 2.444\n",
      "Epoch [1][10/453]\tTrain Loss: 2.455\n",
      "Epoch [1][15/453]\tTrain Loss: 2.460\n",
      "Epoch [1][20/453]\tTrain Loss: 2.457\n",
      "Epoch [1][25/453]\tTrain Loss: 2.452\n",
      "Epoch [1][30/453]\tTrain Loss: 2.448\n",
      "Epoch [1][35/453]\tTrain Loss: 2.446\n",
      "Epoch [1][40/453]\tTrain Loss: 2.459\n",
      "Epoch [1][45/453]\tTrain Loss: 2.454\n",
      "Epoch [1][50/453]\tTrain Loss: 2.453\n",
      "Epoch [1][55/453]\tTrain Loss: 2.458\n",
      "Epoch [1][60/453]\tTrain Loss: 2.460\n",
      "Epoch [1][65/453]\tTrain Loss: 2.461\n",
      "Epoch [1][70/453]\tTrain Loss: 2.462\n",
      "Epoch [1][75/453]\tTrain Loss: 2.462\n",
      "Epoch [1][80/453]\tTrain Loss: 2.465\n",
      "Epoch [1][85/453]\tTrain Loss: 2.466\n",
      "Epoch [1][90/453]\tTrain Loss: 2.460\n",
      "Epoch [1][95/453]\tTrain Loss: 2.459\n",
      "Epoch [1][100/453]\tTrain Loss: 2.459\n",
      "Epoch [1][105/453]\tTrain Loss: 2.456\n",
      "Epoch [1][110/453]\tTrain Loss: 2.457\n",
      "Epoch [1][115/453]\tTrain Loss: 2.454\n",
      "Epoch [1][120/453]\tTrain Loss: 2.454\n",
      "Epoch [1][125/453]\tTrain Loss: 2.453\n",
      "Epoch [1][130/453]\tTrain Loss: 2.451\n",
      "Epoch [1][135/453]\tTrain Loss: 2.453\n",
      "Epoch [1][140/453]\tTrain Loss: 2.453\n",
      "Epoch [1][145/453]\tTrain Loss: 2.449\n",
      "Epoch [1][150/453]\tTrain Loss: 2.450\n",
      "Epoch [1][155/453]\tTrain Loss: 2.448\n",
      "Epoch [1][160/453]\tTrain Loss: 2.447\n",
      "Epoch [1][165/453]\tTrain Loss: 2.444\n",
      "Epoch [1][170/453]\tTrain Loss: 2.442\n",
      "Epoch [1][175/453]\tTrain Loss: 2.441\n",
      "Epoch [1][180/453]\tTrain Loss: 2.439\n",
      "Epoch [1][185/453]\tTrain Loss: 2.438\n",
      "Epoch [1][190/453]\tTrain Loss: 2.436\n",
      "Epoch [1][195/453]\tTrain Loss: 2.432\n",
      "Epoch [1][200/453]\tTrain Loss: 2.432\n",
      "Epoch [1][205/453]\tTrain Loss: 2.433\n",
      "Epoch [1][210/453]\tTrain Loss: 2.431\n",
      "Epoch [1][215/453]\tTrain Loss: 2.429\n",
      "Epoch [1][220/453]\tTrain Loss: 2.429\n",
      "Epoch [1][225/453]\tTrain Loss: 2.427\n",
      "Epoch [1][230/453]\tTrain Loss: 2.427\n",
      "Epoch [1][235/453]\tTrain Loss: 2.427\n",
      "Epoch [1][240/453]\tTrain Loss: 2.426\n",
      "Epoch [1][245/453]\tTrain Loss: 2.425\n",
      "Epoch [1][250/453]\tTrain Loss: 2.424\n",
      "Epoch [1][255/453]\tTrain Loss: 2.422\n",
      "Epoch [1][260/453]\tTrain Loss: 2.422\n",
      "Epoch [1][265/453]\tTrain Loss: 2.420\n",
      "Epoch [1][270/453]\tTrain Loss: 2.420\n",
      "Epoch [1][275/453]\tTrain Loss: 2.418\n",
      "Epoch [1][280/453]\tTrain Loss: 2.418\n",
      "Epoch [1][285/453]\tTrain Loss: 2.418\n",
      "Epoch [1][290/453]\tTrain Loss: 2.417\n",
      "Epoch [1][295/453]\tTrain Loss: 2.415\n",
      "Epoch [1][300/453]\tTrain Loss: 2.414\n",
      "Epoch [1][305/453]\tTrain Loss: 2.413\n",
      "Epoch [1][310/453]\tTrain Loss: 2.413\n",
      "Epoch [1][315/453]\tTrain Loss: 2.413\n",
      "Epoch [1][320/453]\tTrain Loss: 2.411\n",
      "Epoch [1][325/453]\tTrain Loss: 2.410\n",
      "Epoch [1][330/453]\tTrain Loss: 2.410\n",
      "Epoch [1][335/453]\tTrain Loss: 2.409\n",
      "Epoch [1][340/453]\tTrain Loss: 2.409\n",
      "Epoch [1][345/453]\tTrain Loss: 2.407\n",
      "Epoch [1][350/453]\tTrain Loss: 2.406\n",
      "Epoch [1][355/453]\tTrain Loss: 2.405\n",
      "Epoch [1][360/453]\tTrain Loss: 2.405\n",
      "Epoch [1][365/453]\tTrain Loss: 2.404\n",
      "Epoch [1][370/453]\tTrain Loss: 2.403\n",
      "Epoch [1][375/453]\tTrain Loss: 2.403\n",
      "Epoch [1][380/453]\tTrain Loss: 2.401\n",
      "Epoch [1][385/453]\tTrain Loss: 2.399\n",
      "Epoch [1][390/453]\tTrain Loss: 2.398\n",
      "Epoch [1][395/453]\tTrain Loss: 2.398\n",
      "Epoch [1][400/453]\tTrain Loss: 2.397\n",
      "Epoch [1][405/453]\tTrain Loss: 2.396\n",
      "Epoch [1][410/453]\tTrain Loss: 2.395\n",
      "Epoch [1][415/453]\tTrain Loss: 2.395\n",
      "Epoch [1][420/453]\tTrain Loss: 2.395\n",
      "Epoch [1][425/453]\tTrain Loss: 2.394\n",
      "Epoch [1][430/453]\tTrain Loss: 2.393\n",
      "Epoch [1][435/453]\tTrain Loss: 2.392\n",
      "Epoch [1][440/453]\tTrain Loss: 2.392\n",
      "Epoch [1][445/453]\tTrain Loss: 2.391\n",
      "Epoch [1][450/453]\tTrain Loss: 2.390\n",
      "Epoch [1][0/15]\t\t\tValid Loss: 2.151\n",
      "Epoch [1][5/15]\t\t\tValid Loss: 2.192\n",
      "Epoch [1][10/15]\t\t\tValid Loss: 2.206\n",
      "\n",
      "Candidate :▁Ein ▁Mann ▁sit z t ▁am ▁Strand ▁und ▁h äl t ▁se ine ▁Hand y .\n",
      "Candidate_labeled :  ['<start>', '▁Ein', '▁Mann', '▁sit', 'z', 't', '▁am', '▁Strand', '▁und', '▁h', 'äl', 't', '▁se', 'ine', '▁Hand', 'y', '.', '</s>']\n",
      "Real :▁Ein ▁Mann ▁sit z t ▁auf ▁ein er ▁Bank ▁w ä hren d ▁er ▁se inen ▁Hun d ▁h äl t ▁und ▁auf s ▁Wasser ▁ blick t .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:09:15.779470 #######\n",
      "\n",
      "Epoch [2][0/453]\tTrain Loss: 2.063\n",
      "Epoch [2][5/453]\tTrain Loss: 2.201\n",
      "Epoch [2][10/453]\tTrain Loss: 2.184\n",
      "Epoch [2][15/453]\tTrain Loss: 2.184\n",
      "Epoch [2][20/453]\tTrain Loss: 2.194\n",
      "Epoch [2][25/453]\tTrain Loss: 2.192\n",
      "Epoch [2][30/453]\tTrain Loss: 2.196\n",
      "Epoch [2][35/453]\tTrain Loss: 2.210\n",
      "Epoch [2][40/453]\tTrain Loss: 2.207\n",
      "Epoch [2][45/453]\tTrain Loss: 2.212\n",
      "Epoch [2][50/453]\tTrain Loss: 2.217\n",
      "Epoch [2][55/453]\tTrain Loss: 2.211\n",
      "Epoch [2][60/453]\tTrain Loss: 2.211\n",
      "Epoch [2][65/453]\tTrain Loss: 2.214\n",
      "Epoch [2][70/453]\tTrain Loss: 2.217\n",
      "Epoch [2][75/453]\tTrain Loss: 2.220\n",
      "Epoch [2][80/453]\tTrain Loss: 2.223\n",
      "Epoch [2][85/453]\tTrain Loss: 2.227\n",
      "Epoch [2][90/453]\tTrain Loss: 2.232\n",
      "Epoch [2][95/453]\tTrain Loss: 2.233\n",
      "Epoch [2][100/453]\tTrain Loss: 2.235\n",
      "Epoch [2][105/453]\tTrain Loss: 2.236\n",
      "Epoch [2][110/453]\tTrain Loss: 2.235\n",
      "Epoch [2][115/453]\tTrain Loss: 2.236\n",
      "Epoch [2][120/453]\tTrain Loss: 2.237\n",
      "Epoch [2][125/453]\tTrain Loss: 2.237\n",
      "Epoch [2][130/453]\tTrain Loss: 2.236\n",
      "Epoch [2][135/453]\tTrain Loss: 2.230\n",
      "Epoch [2][140/453]\tTrain Loss: 2.232\n",
      "Epoch [2][145/453]\tTrain Loss: 2.231\n",
      "Epoch [2][150/453]\tTrain Loss: 2.231\n",
      "Epoch [2][155/453]\tTrain Loss: 2.228\n",
      "Epoch [2][160/453]\tTrain Loss: 2.226\n",
      "Epoch [2][165/453]\tTrain Loss: 2.226\n",
      "Epoch [2][170/453]\tTrain Loss: 2.227\n",
      "Epoch [2][175/453]\tTrain Loss: 2.227\n",
      "Epoch [2][180/453]\tTrain Loss: 2.226\n",
      "Epoch [2][185/453]\tTrain Loss: 2.223\n",
      "Epoch [2][190/453]\tTrain Loss: 2.222\n",
      "Epoch [2][195/453]\tTrain Loss: 2.224\n",
      "Epoch [2][200/453]\tTrain Loss: 2.223\n",
      "Epoch [2][205/453]\tTrain Loss: 2.221\n",
      "Epoch [2][210/453]\tTrain Loss: 2.221\n",
      "Epoch [2][215/453]\tTrain Loss: 2.222\n",
      "Epoch [2][220/453]\tTrain Loss: 2.221\n",
      "Epoch [2][225/453]\tTrain Loss: 2.223\n",
      "Epoch [2][230/453]\tTrain Loss: 2.222\n",
      "Epoch [2][235/453]\tTrain Loss: 2.220\n",
      "Epoch [2][240/453]\tTrain Loss: 2.221\n",
      "Epoch [2][245/453]\tTrain Loss: 2.220\n",
      "Epoch [2][250/453]\tTrain Loss: 2.220\n",
      "Epoch [2][255/453]\tTrain Loss: 2.220\n",
      "Epoch [2][260/453]\tTrain Loss: 2.219\n",
      "Epoch [2][265/453]\tTrain Loss: 2.217\n",
      "Epoch [2][270/453]\tTrain Loss: 2.216\n",
      "Epoch [2][275/453]\tTrain Loss: 2.215\n",
      "Epoch [2][280/453]\tTrain Loss: 2.214\n",
      "Epoch [2][285/453]\tTrain Loss: 2.212\n",
      "Epoch [2][290/453]\tTrain Loss: 2.212\n",
      "Epoch [2][295/453]\tTrain Loss: 2.211\n",
      "Epoch [2][300/453]\tTrain Loss: 2.211\n",
      "Epoch [2][305/453]\tTrain Loss: 2.210\n",
      "Epoch [2][310/453]\tTrain Loss: 2.210\n",
      "Epoch [2][315/453]\tTrain Loss: 2.209\n",
      "Epoch [2][320/453]\tTrain Loss: 2.209\n",
      "Epoch [2][325/453]\tTrain Loss: 2.207\n",
      "Epoch [2][330/453]\tTrain Loss: 2.206\n",
      "Epoch [2][335/453]\tTrain Loss: 2.207\n",
      "Epoch [2][340/453]\tTrain Loss: 2.205\n",
      "Epoch [2][345/453]\tTrain Loss: 2.205\n",
      "Epoch [2][350/453]\tTrain Loss: 2.204\n",
      "Epoch [2][355/453]\tTrain Loss: 2.204\n",
      "Epoch [2][360/453]\tTrain Loss: 2.203\n",
      "Epoch [2][365/453]\tTrain Loss: 2.202\n",
      "Epoch [2][370/453]\tTrain Loss: 2.202\n",
      "Epoch [2][375/453]\tTrain Loss: 2.202\n",
      "Epoch [2][380/453]\tTrain Loss: 2.201\n",
      "Epoch [2][385/453]\tTrain Loss: 2.201\n",
      "Epoch [2][390/453]\tTrain Loss: 2.200\n",
      "Epoch [2][395/453]\tTrain Loss: 2.200\n",
      "Epoch [2][400/453]\tTrain Loss: 2.200\n",
      "Epoch [2][405/453]\tTrain Loss: 2.199\n",
      "Epoch [2][410/453]\tTrain Loss: 2.197\n",
      "Epoch [2][415/453]\tTrain Loss: 2.197\n",
      "Epoch [2][420/453]\tTrain Loss: 2.196\n",
      "Epoch [2][425/453]\tTrain Loss: 2.197\n",
      "Epoch [2][430/453]\tTrain Loss: 2.197\n",
      "Epoch [2][435/453]\tTrain Loss: 2.196\n",
      "Epoch [2][440/453]\tTrain Loss: 2.196\n",
      "Epoch [2][445/453]\tTrain Loss: 2.195\n",
      "Epoch [2][450/453]\tTrain Loss: 2.195\n",
      "Epoch [2][0/15]\t\t\tValid Loss: 2.051\n",
      "Epoch [2][5/15]\t\t\tValid Loss: 2.082\n",
      "Epoch [2][10/15]\t\t\tValid Loss: 2.110\n",
      "\n",
      "Candidate :▁Ein ▁Mann ▁in ▁eine m ▁rot en ▁Pull over ▁spi elt ▁am ▁Strand .\n",
      "Candidate_labeled :  ['<start>', '▁Ein', '▁Mann', '▁in', '▁eine', 'm', '▁rot', 'en', '▁Pull', 'over', '▁spi', 'elt', '▁am', '▁Strand', '.', '</s>']\n",
      "Real :▁Ein ▁Mann ▁in ▁Jean s ▁spi elt ▁an ▁eine m ▁Strand ▁mit ▁eine m ▁rot en ▁Ball .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:09:14.165138 #######\n",
      "\n",
      "Epoch [3][0/453]\tTrain Loss: 1.939\n",
      "Epoch [3][5/453]\tTrain Loss: 2.017\n",
      "Epoch [3][10/453]\tTrain Loss: 2.062\n",
      "Epoch [3][15/453]\tTrain Loss: 2.046\n",
      "Epoch [3][20/453]\tTrain Loss: 2.037\n",
      "Epoch [3][25/453]\tTrain Loss: 2.054\n",
      "Epoch [3][30/453]\tTrain Loss: 2.059\n",
      "Epoch [3][35/453]\tTrain Loss: 2.046\n",
      "Epoch [3][40/453]\tTrain Loss: 2.035\n",
      "Epoch [3][45/453]\tTrain Loss: 2.037\n",
      "Epoch [3][50/453]\tTrain Loss: 2.032\n",
      "Epoch [3][55/453]\tTrain Loss: 2.032\n",
      "Epoch [3][60/453]\tTrain Loss: 2.037\n",
      "Epoch [3][65/453]\tTrain Loss: 2.038\n",
      "Epoch [3][70/453]\tTrain Loss: 2.040\n",
      "Epoch [3][75/453]\tTrain Loss: 2.040\n",
      "Epoch [3][80/453]\tTrain Loss: 2.036\n",
      "Epoch [3][85/453]\tTrain Loss: 2.035\n",
      "Epoch [3][90/453]\tTrain Loss: 2.032\n",
      "Epoch [3][95/453]\tTrain Loss: 2.036\n",
      "Epoch [3][100/453]\tTrain Loss: 2.036\n",
      "Epoch [3][105/453]\tTrain Loss: 2.039\n",
      "Epoch [3][110/453]\tTrain Loss: 2.043\n",
      "Epoch [3][115/453]\tTrain Loss: 2.046\n",
      "Epoch [3][120/453]\tTrain Loss: 2.048\n",
      "Epoch [3][125/453]\tTrain Loss: 2.050\n",
      "Epoch [3][130/453]\tTrain Loss: 2.050\n",
      "Epoch [3][135/453]\tTrain Loss: 2.050\n",
      "Epoch [3][140/453]\tTrain Loss: 2.051\n",
      "Epoch [3][145/453]\tTrain Loss: 2.051\n",
      "Epoch [3][150/453]\tTrain Loss: 2.053\n",
      "Epoch [3][155/453]\tTrain Loss: 2.054\n",
      "Epoch [3][160/453]\tTrain Loss: 2.055\n",
      "Epoch [3][165/453]\tTrain Loss: 2.055\n",
      "Epoch [3][170/453]\tTrain Loss: 2.054\n",
      "Epoch [3][175/453]\tTrain Loss: 2.055\n",
      "Epoch [3][180/453]\tTrain Loss: 2.056\n",
      "Epoch [3][185/453]\tTrain Loss: 2.055\n",
      "Epoch [3][190/453]\tTrain Loss: 2.054\n",
      "Epoch [3][195/453]\tTrain Loss: 2.051\n",
      "Epoch [3][200/453]\tTrain Loss: 2.055\n",
      "Epoch [3][205/453]\tTrain Loss: 2.056\n",
      "Epoch [3][210/453]\tTrain Loss: 2.056\n",
      "Epoch [3][215/453]\tTrain Loss: 2.054\n",
      "Epoch [3][220/453]\tTrain Loss: 2.054\n",
      "Epoch [3][225/453]\tTrain Loss: 2.053\n",
      "Epoch [3][230/453]\tTrain Loss: 2.053\n",
      "Epoch [3][235/453]\tTrain Loss: 2.053\n",
      "Epoch [3][240/453]\tTrain Loss: 2.051\n",
      "Epoch [3][245/453]\tTrain Loss: 2.051\n",
      "Epoch [3][250/453]\tTrain Loss: 2.052\n",
      "Epoch [3][255/453]\tTrain Loss: 2.052\n",
      "Epoch [3][260/453]\tTrain Loss: 2.052\n",
      "Epoch [3][265/453]\tTrain Loss: 2.051\n",
      "Epoch [3][270/453]\tTrain Loss: 2.050\n",
      "Epoch [3][275/453]\tTrain Loss: 2.051\n",
      "Epoch [3][280/453]\tTrain Loss: 2.051\n",
      "Epoch [3][285/453]\tTrain Loss: 2.050\n",
      "Epoch [3][290/453]\tTrain Loss: 2.051\n",
      "Epoch [3][295/453]\tTrain Loss: 2.051\n",
      "Epoch [3][300/453]\tTrain Loss: 2.050\n",
      "Epoch [3][305/453]\tTrain Loss: 2.050\n",
      "Epoch [3][310/453]\tTrain Loss: 2.051\n",
      "Epoch [3][315/453]\tTrain Loss: 2.051\n",
      "Epoch [3][320/453]\tTrain Loss: 2.051\n",
      "Epoch [3][325/453]\tTrain Loss: 2.051\n",
      "Epoch [3][330/453]\tTrain Loss: 2.051\n",
      "Epoch [3][335/453]\tTrain Loss: 2.051\n",
      "Epoch [3][340/453]\tTrain Loss: 2.051\n",
      "Epoch [3][345/453]\tTrain Loss: 2.051\n",
      "Epoch [3][350/453]\tTrain Loss: 2.051\n",
      "Epoch [3][355/453]\tTrain Loss: 2.050\n",
      "Epoch [3][360/453]\tTrain Loss: 2.049\n",
      "Epoch [3][365/453]\tTrain Loss: 2.049\n",
      "Epoch [3][370/453]\tTrain Loss: 2.048\n",
      "Epoch [3][375/453]\tTrain Loss: 2.047\n",
      "Epoch [3][380/453]\tTrain Loss: 2.047\n",
      "Epoch [3][385/453]\tTrain Loss: 2.047\n",
      "Epoch [3][390/453]\tTrain Loss: 2.047\n",
      "Epoch [3][395/453]\tTrain Loss: 2.047\n",
      "Epoch [3][400/453]\tTrain Loss: 2.047\n",
      "Epoch [3][405/453]\tTrain Loss: 2.046\n",
      "Epoch [3][410/453]\tTrain Loss: 2.046\n",
      "Epoch [3][415/453]\tTrain Loss: 2.046\n",
      "Epoch [3][420/453]\tTrain Loss: 2.046\n",
      "Epoch [3][425/453]\tTrain Loss: 2.045\n",
      "Epoch [3][430/453]\tTrain Loss: 2.044\n",
      "Epoch [3][435/453]\tTrain Loss: 2.044\n",
      "Epoch [3][440/453]\tTrain Loss: 2.044\n",
      "Epoch [3][445/453]\tTrain Loss: 2.044\n",
      "Epoch [3][450/453]\tTrain Loss: 2.044\n",
      "Epoch [3][0/15]\t\t\tValid Loss: 1.962\n",
      "Epoch [3][5/15]\t\t\tValid Loss: 1.927\n",
      "Epoch [3][10/15]\t\t\tValid Loss: 1.974\n",
      "\n",
      "Candidate :▁Frauen ▁in ▁Tar n kle id ung ▁ arbeit en ▁in ▁eine m ▁Rau m .\n",
      "Candidate_labeled :  ['<start>', '▁Frauen', '▁in', '▁Tar', 'n', 'kle', 'id', 'ung', '▁', 'arbeit', 'en', '▁in', '▁eine', 'm', '▁Rau', 'm', '.', '</s>']\n",
      "Real :▁Frauen , ▁die ▁tradition elle ▁Kle id ung ▁tra gen , ▁ spiel en ▁das ▁Leben ▁Ein heim ischer ▁nach .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:09:13.216465 #######\n",
      "\n",
      "Epoch [4][0/453]\tTrain Loss: 1.815\n",
      "Epoch [4][5/453]\tTrain Loss: 1.890\n",
      "Epoch [4][10/453]\tTrain Loss: 1.913\n",
      "Epoch [4][15/453]\tTrain Loss: 1.911\n",
      "Epoch [4][20/453]\tTrain Loss: 1.916\n",
      "Epoch [4][25/453]\tTrain Loss: 1.909\n",
      "Epoch [4][30/453]\tTrain Loss: 1.909\n",
      "Epoch [4][35/453]\tTrain Loss: 1.915\n",
      "Epoch [4][40/453]\tTrain Loss: 1.910\n",
      "Epoch [4][45/453]\tTrain Loss: 1.912\n",
      "Epoch [4][50/453]\tTrain Loss: 1.920\n",
      "Epoch [4][55/453]\tTrain Loss: 1.919\n",
      "Epoch [4][60/453]\tTrain Loss: 1.919\n",
      "Epoch [4][65/453]\tTrain Loss: 1.918\n",
      "Epoch [4][70/453]\tTrain Loss: 1.923\n",
      "Epoch [4][75/453]\tTrain Loss: 1.924\n",
      "Epoch [4][80/453]\tTrain Loss: 1.928\n",
      "Epoch [4][85/453]\tTrain Loss: 1.930\n",
      "Epoch [4][90/453]\tTrain Loss: 1.925\n",
      "Epoch [4][95/453]\tTrain Loss: 1.927\n",
      "Epoch [4][100/453]\tTrain Loss: 1.928\n",
      "Epoch [4][105/453]\tTrain Loss: 1.927\n",
      "Epoch [4][110/453]\tTrain Loss: 1.926\n",
      "Epoch [4][115/453]\tTrain Loss: 1.925\n",
      "Epoch [4][120/453]\tTrain Loss: 1.924\n",
      "Epoch [4][125/453]\tTrain Loss: 1.924\n",
      "Epoch [4][130/453]\tTrain Loss: 1.923\n",
      "Epoch [4][135/453]\tTrain Loss: 1.924\n",
      "Epoch [4][140/453]\tTrain Loss: 1.922\n",
      "Epoch [4][145/453]\tTrain Loss: 1.923\n",
      "Epoch [4][150/453]\tTrain Loss: 1.924\n",
      "Epoch [4][155/453]\tTrain Loss: 1.925\n",
      "Epoch [4][160/453]\tTrain Loss: 1.925\n",
      "Epoch [4][165/453]\tTrain Loss: 1.924\n",
      "Epoch [4][170/453]\tTrain Loss: 1.924\n",
      "Epoch [4][175/453]\tTrain Loss: 1.925\n",
      "Epoch [4][180/453]\tTrain Loss: 1.927\n",
      "Epoch [4][185/453]\tTrain Loss: 1.927\n",
      "Epoch [4][190/453]\tTrain Loss: 1.926\n",
      "Epoch [4][195/453]\tTrain Loss: 1.929\n",
      "Epoch [4][200/453]\tTrain Loss: 1.930\n",
      "Epoch [4][205/453]\tTrain Loss: 1.931\n",
      "Epoch [4][210/453]\tTrain Loss: 1.931\n",
      "Epoch [4][215/453]\tTrain Loss: 1.931\n",
      "Epoch [4][220/453]\tTrain Loss: 1.932\n",
      "Epoch [4][225/453]\tTrain Loss: 1.933\n",
      "Epoch [4][230/453]\tTrain Loss: 1.934\n",
      "Epoch [4][235/453]\tTrain Loss: 1.933\n",
      "Epoch [4][240/453]\tTrain Loss: 1.932\n",
      "Epoch [4][245/453]\tTrain Loss: 1.930\n",
      "Epoch [4][250/453]\tTrain Loss: 1.928\n",
      "Epoch [4][255/453]\tTrain Loss: 1.930\n",
      "Epoch [4][260/453]\tTrain Loss: 1.928\n",
      "Epoch [4][265/453]\tTrain Loss: 1.928\n",
      "Epoch [4][270/453]\tTrain Loss: 1.929\n",
      "Epoch [4][275/453]\tTrain Loss: 1.930\n",
      "Epoch [4][280/453]\tTrain Loss: 1.929\n",
      "Epoch [4][285/453]\tTrain Loss: 1.930\n",
      "Epoch [4][290/453]\tTrain Loss: 1.930\n",
      "Epoch [4][295/453]\tTrain Loss: 1.932\n",
      "Epoch [4][300/453]\tTrain Loss: 1.933\n",
      "Epoch [4][305/453]\tTrain Loss: 1.933\n",
      "Epoch [4][310/453]\tTrain Loss: 1.933\n",
      "Epoch [4][315/453]\tTrain Loss: 1.934\n",
      "Epoch [4][320/453]\tTrain Loss: 1.934\n",
      "Epoch [4][325/453]\tTrain Loss: 1.933\n",
      "Epoch [4][330/453]\tTrain Loss: 1.933\n",
      "Epoch [4][335/453]\tTrain Loss: 1.933\n",
      "Epoch [4][340/453]\tTrain Loss: 1.932\n",
      "Epoch [4][345/453]\tTrain Loss: 1.933\n",
      "Epoch [4][350/453]\tTrain Loss: 1.933\n",
      "Epoch [4][355/453]\tTrain Loss: 1.933\n",
      "Epoch [4][360/453]\tTrain Loss: 1.933\n",
      "Epoch [4][365/453]\tTrain Loss: 1.933\n",
      "Epoch [4][370/453]\tTrain Loss: 1.932\n",
      "Epoch [4][375/453]\tTrain Loss: 1.932\n",
      "Epoch [4][380/453]\tTrain Loss: 1.932\n",
      "Epoch [4][385/453]\tTrain Loss: 1.931\n",
      "Epoch [4][390/453]\tTrain Loss: 1.932\n",
      "Epoch [4][395/453]\tTrain Loss: 1.932\n",
      "Epoch [4][400/453]\tTrain Loss: 1.932\n",
      "Epoch [4][405/453]\tTrain Loss: 1.931\n",
      "Epoch [4][410/453]\tTrain Loss: 1.931\n",
      "Epoch [4][415/453]\tTrain Loss: 1.932\n",
      "Epoch [4][420/453]\tTrain Loss: 1.932\n",
      "Epoch [4][425/453]\tTrain Loss: 1.932\n",
      "Epoch [4][430/453]\tTrain Loss: 1.932\n",
      "Epoch [4][435/453]\tTrain Loss: 1.932\n",
      "Epoch [4][440/453]\tTrain Loss: 1.932\n",
      "Epoch [4][445/453]\tTrain Loss: 1.931\n",
      "Epoch [4][450/453]\tTrain Loss: 1.930\n",
      "Epoch [4][0/15]\t\t\tValid Loss: 1.826\n",
      "Epoch [4][5/15]\t\t\tValid Loss: 1.879\n",
      "Epoch [4][10/15]\t\t\tValid Loss: 1.888\n",
      "\n",
      "Candidate :▁D rei ▁Jung en ▁in ▁Bad e anz ü gen ▁ste hen ▁auf ▁dem ▁Bo den .\n",
      "Candidate_labeled :  ['<start>', '▁D', 'rei', '▁Jung', 'en', '▁in', '▁Bad', 'e', 'anz', 'ü', 'gen', '▁ste', 'hen', '▁auf', '▁dem', '▁Bo', 'den', '.', '</s>']\n",
      "Real :▁3 ▁Jung en ▁ste hen ▁in ▁i hren ▁Bad e ho sen ▁auf ▁eine m ▁Pier .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:09:14.564518 #######\n",
      "\n",
      "Epoch [5][0/453]\tTrain Loss: 1.836\n",
      "Epoch [5][5/453]\tTrain Loss: 1.900\n",
      "Epoch [5][10/453]\tTrain Loss: 1.828\n",
      "Epoch [5][15/453]\tTrain Loss: 1.819\n",
      "Epoch [5][20/453]\tTrain Loss: 1.828\n",
      "Epoch [5][25/453]\tTrain Loss: 1.835\n",
      "Epoch [5][30/453]\tTrain Loss: 1.832\n",
      "Epoch [5][35/453]\tTrain Loss: 1.827\n",
      "Epoch [5][40/453]\tTrain Loss: 1.832\n",
      "Epoch [5][45/453]\tTrain Loss: 1.828\n",
      "Epoch [5][50/453]\tTrain Loss: 1.825\n",
      "Epoch [5][55/453]\tTrain Loss: 1.820\n",
      "Epoch [5][60/453]\tTrain Loss: 1.823\n",
      "Epoch [5][65/453]\tTrain Loss: 1.823\n",
      "Epoch [5][70/453]\tTrain Loss: 1.832\n",
      "Epoch [5][75/453]\tTrain Loss: 1.833\n",
      "Epoch [5][80/453]\tTrain Loss: 1.836\n",
      "Epoch [5][85/453]\tTrain Loss: 1.843\n",
      "Epoch [5][90/453]\tTrain Loss: 1.842\n",
      "Epoch [5][95/453]\tTrain Loss: 1.846\n",
      "Epoch [5][100/453]\tTrain Loss: 1.849\n",
      "Epoch [5][105/453]\tTrain Loss: 1.846\n",
      "Epoch [5][110/453]\tTrain Loss: 1.846\n",
      "Epoch [5][115/453]\tTrain Loss: 1.845\n",
      "Epoch [5][120/453]\tTrain Loss: 1.844\n",
      "Epoch [5][125/453]\tTrain Loss: 1.841\n",
      "Epoch [5][130/453]\tTrain Loss: 1.840\n",
      "Epoch [5][135/453]\tTrain Loss: 1.840\n",
      "Epoch [5][140/453]\tTrain Loss: 1.841\n",
      "Epoch [5][145/453]\tTrain Loss: 1.840\n",
      "Epoch [5][150/453]\tTrain Loss: 1.844\n",
      "Epoch [5][155/453]\tTrain Loss: 1.846\n",
      "Epoch [5][160/453]\tTrain Loss: 1.844\n",
      "Epoch [5][165/453]\tTrain Loss: 1.844\n",
      "Epoch [5][170/453]\tTrain Loss: 1.842\n",
      "Epoch [5][175/453]\tTrain Loss: 1.841\n",
      "Epoch [5][180/453]\tTrain Loss: 1.842\n",
      "Epoch [5][185/453]\tTrain Loss: 1.842\n",
      "Epoch [5][190/453]\tTrain Loss: 1.842\n",
      "Epoch [5][195/453]\tTrain Loss: 1.842\n",
      "Epoch [5][200/453]\tTrain Loss: 1.842\n",
      "Epoch [5][205/453]\tTrain Loss: 1.841\n",
      "Epoch [5][210/453]\tTrain Loss: 1.842\n",
      "Epoch [5][215/453]\tTrain Loss: 1.842\n",
      "Epoch [5][220/453]\tTrain Loss: 1.841\n",
      "Epoch [5][225/453]\tTrain Loss: 1.843\n",
      "Epoch [5][230/453]\tTrain Loss: 1.843\n",
      "Epoch [5][235/453]\tTrain Loss: 1.843\n",
      "Epoch [5][240/453]\tTrain Loss: 1.843\n",
      "Epoch [5][245/453]\tTrain Loss: 1.841\n",
      "Epoch [5][250/453]\tTrain Loss: 1.842\n",
      "Epoch [5][255/453]\tTrain Loss: 1.842\n",
      "Epoch [5][260/453]\tTrain Loss: 1.842\n",
      "Epoch [5][265/453]\tTrain Loss: 1.842\n",
      "Epoch [5][270/453]\tTrain Loss: 1.842\n",
      "Epoch [5][275/453]\tTrain Loss: 1.841\n",
      "Epoch [5][280/453]\tTrain Loss: 1.842\n",
      "Epoch [5][285/453]\tTrain Loss: 1.840\n",
      "Epoch [5][290/453]\tTrain Loss: 1.839\n",
      "Epoch [5][295/453]\tTrain Loss: 1.839\n",
      "Epoch [5][300/453]\tTrain Loss: 1.838\n",
      "Epoch [5][305/453]\tTrain Loss: 1.838\n",
      "Epoch [5][310/453]\tTrain Loss: 1.839\n",
      "Epoch [5][315/453]\tTrain Loss: 1.838\n",
      "Epoch [5][320/453]\tTrain Loss: 1.838\n",
      "Epoch [5][325/453]\tTrain Loss: 1.837\n",
      "Epoch [5][330/453]\tTrain Loss: 1.837\n",
      "Epoch [5][335/453]\tTrain Loss: 1.837\n",
      "Epoch [5][340/453]\tTrain Loss: 1.837\n",
      "Epoch [5][345/453]\tTrain Loss: 1.838\n",
      "Epoch [5][350/453]\tTrain Loss: 1.839\n",
      "Epoch [5][355/453]\tTrain Loss: 1.839\n",
      "Epoch [5][360/453]\tTrain Loss: 1.839\n",
      "Epoch [5][365/453]\tTrain Loss: 1.839\n",
      "Epoch [5][370/453]\tTrain Loss: 1.838\n",
      "Epoch [5][375/453]\tTrain Loss: 1.838\n",
      "Epoch [5][380/453]\tTrain Loss: 1.839\n",
      "Epoch [5][385/453]\tTrain Loss: 1.838\n",
      "Epoch [5][390/453]\tTrain Loss: 1.838\n",
      "Epoch [5][395/453]\tTrain Loss: 1.836\n",
      "Epoch [5][400/453]\tTrain Loss: 1.837\n",
      "Epoch [5][405/453]\tTrain Loss: 1.838\n",
      "Epoch [5][410/453]\tTrain Loss: 1.836\n",
      "Epoch [5][415/453]\tTrain Loss: 1.836\n",
      "Epoch [5][420/453]\tTrain Loss: 1.836\n",
      "Epoch [5][425/453]\tTrain Loss: 1.836\n",
      "Epoch [5][430/453]\tTrain Loss: 1.835\n",
      "Epoch [5][435/453]\tTrain Loss: 1.835\n",
      "Epoch [5][440/453]\tTrain Loss: 1.836\n",
      "Epoch [5][445/453]\tTrain Loss: 1.835\n",
      "Epoch [5][450/453]\tTrain Loss: 1.835\n",
      "Epoch [5][0/15]\t\t\tValid Loss: 1.834\n",
      "Epoch [5][5/15]\t\t\tValid Loss: 1.817\n",
      "Epoch [5][10/15]\t\t\tValid Loss: 1.818\n",
      "\n",
      "Candidate :▁Ein ▁Mä d chen ▁in ▁ein er ▁West e ▁sch lä ft ▁in ▁eine m ▁Wasser .\n",
      "Candidate_labeled :  ['<start>', '▁Ein', '▁Mä', 'd', 'chen', '▁in', '▁ein', 'er', '▁West', 'e', '▁sch', 'lä', 'ft', '▁in', '▁eine', 'm', '▁Wasser', '.', '</s>']\n",
      "Real :▁Ein ▁Mä d chen ▁in ▁ein er ▁R ett ungs west e ▁t re ib t ▁im ▁Wasser .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:09:16.124036 #######\n",
      "\n",
      "Epoch [6][0/453]\tTrain Loss: 1.655\n",
      "Epoch [6][5/453]\tTrain Loss: 1.713\n",
      "Epoch [6][10/453]\tTrain Loss: 1.705\n",
      "Epoch [6][15/453]\tTrain Loss: 1.714\n",
      "Epoch [6][20/453]\tTrain Loss: 1.703\n",
      "Epoch [6][25/453]\tTrain Loss: 1.721\n",
      "Epoch [6][30/453]\tTrain Loss: 1.715\n",
      "Epoch [6][35/453]\tTrain Loss: 1.710\n",
      "Epoch [6][40/453]\tTrain Loss: 1.712\n",
      "Epoch [6][45/453]\tTrain Loss: 1.709\n",
      "Epoch [6][50/453]\tTrain Loss: 1.711\n",
      "Epoch [6][55/453]\tTrain Loss: 1.703\n",
      "Epoch [6][60/453]\tTrain Loss: 1.707\n",
      "Epoch [6][65/453]\tTrain Loss: 1.705\n",
      "Epoch [6][70/453]\tTrain Loss: 1.705\n",
      "Epoch [6][75/453]\tTrain Loss: 1.707\n",
      "Epoch [6][80/453]\tTrain Loss: 1.715\n",
      "Epoch [6][85/453]\tTrain Loss: 1.719\n",
      "Epoch [6][90/453]\tTrain Loss: 1.718\n",
      "Epoch [6][95/453]\tTrain Loss: 1.719\n",
      "Epoch [6][100/453]\tTrain Loss: 1.719\n",
      "Epoch [6][105/453]\tTrain Loss: 1.717\n",
      "Epoch [6][110/453]\tTrain Loss: 1.716\n",
      "Epoch [6][115/453]\tTrain Loss: 1.717\n",
      "Epoch [6][120/453]\tTrain Loss: 1.718\n",
      "Epoch [6][125/453]\tTrain Loss: 1.716\n",
      "Epoch [6][130/453]\tTrain Loss: 1.716\n",
      "Epoch [6][135/453]\tTrain Loss: 1.717\n",
      "Epoch [6][140/453]\tTrain Loss: 1.716\n",
      "Epoch [6][145/453]\tTrain Loss: 1.717\n",
      "Epoch [6][150/453]\tTrain Loss: 1.716\n",
      "Epoch [6][155/453]\tTrain Loss: 1.715\n",
      "Epoch [6][160/453]\tTrain Loss: 1.717\n",
      "Epoch [6][165/453]\tTrain Loss: 1.718\n",
      "Epoch [6][170/453]\tTrain Loss: 1.716\n",
      "Epoch [6][175/453]\tTrain Loss: 1.716\n",
      "Epoch [6][180/453]\tTrain Loss: 1.715\n",
      "Epoch [6][185/453]\tTrain Loss: 1.715\n",
      "Epoch [6][190/453]\tTrain Loss: 1.715\n",
      "Epoch [6][195/453]\tTrain Loss: 1.714\n",
      "Epoch [6][200/453]\tTrain Loss: 1.714\n",
      "Epoch [6][205/453]\tTrain Loss: 1.715\n",
      "Epoch [6][210/453]\tTrain Loss: 1.717\n",
      "Epoch [6][215/453]\tTrain Loss: 1.716\n",
      "Epoch [6][220/453]\tTrain Loss: 1.717\n",
      "Epoch [6][225/453]\tTrain Loss: 1.717\n",
      "Epoch [6][230/453]\tTrain Loss: 1.718\n",
      "Epoch [6][235/453]\tTrain Loss: 1.720\n",
      "Epoch [6][240/453]\tTrain Loss: 1.720\n",
      "Epoch [6][245/453]\tTrain Loss: 1.721\n",
      "Epoch [6][250/453]\tTrain Loss: 1.722\n",
      "Epoch [6][255/453]\tTrain Loss: 1.722\n",
      "Epoch [6][260/453]\tTrain Loss: 1.723\n",
      "Epoch [6][265/453]\tTrain Loss: 1.725\n",
      "Epoch [6][270/453]\tTrain Loss: 1.723\n",
      "Epoch [6][275/453]\tTrain Loss: 1.723\n",
      "Epoch [6][280/453]\tTrain Loss: 1.724\n",
      "Epoch [6][285/453]\tTrain Loss: 1.725\n",
      "Epoch [6][290/453]\tTrain Loss: 1.725\n",
      "Epoch [6][295/453]\tTrain Loss: 1.725\n",
      "Epoch [6][300/453]\tTrain Loss: 1.723\n",
      "Epoch [6][305/453]\tTrain Loss: 1.725\n",
      "Epoch [6][310/453]\tTrain Loss: 1.724\n",
      "Epoch [6][315/453]\tTrain Loss: 1.724\n",
      "Epoch [6][320/453]\tTrain Loss: 1.725\n",
      "Epoch [6][325/453]\tTrain Loss: 1.725\n",
      "Epoch [6][330/453]\tTrain Loss: 1.724\n",
      "Epoch [6][335/453]\tTrain Loss: 1.723\n",
      "Epoch [6][340/453]\tTrain Loss: 1.725\n",
      "Epoch [6][345/453]\tTrain Loss: 1.726\n",
      "Epoch [6][350/453]\tTrain Loss: 1.727\n",
      "Epoch [6][355/453]\tTrain Loss: 1.727\n",
      "Epoch [6][360/453]\tTrain Loss: 1.727\n",
      "Epoch [6][365/453]\tTrain Loss: 1.727\n",
      "Epoch [6][370/453]\tTrain Loss: 1.727\n",
      "Epoch [6][375/453]\tTrain Loss: 1.728\n",
      "Epoch [6][380/453]\tTrain Loss: 1.729\n",
      "Epoch [6][385/453]\tTrain Loss: 1.728\n",
      "Epoch [6][390/453]\tTrain Loss: 1.728\n",
      "Epoch [6][395/453]\tTrain Loss: 1.729\n",
      "Epoch [6][400/453]\tTrain Loss: 1.729\n",
      "Epoch [6][405/453]\tTrain Loss: 1.729\n",
      "Epoch [6][410/453]\tTrain Loss: 1.730\n",
      "Epoch [6][415/453]\tTrain Loss: 1.730\n",
      "Epoch [6][420/453]\tTrain Loss: 1.730\n",
      "Epoch [6][425/453]\tTrain Loss: 1.729\n",
      "Epoch [6][430/453]\tTrain Loss: 1.729\n",
      "Epoch [6][435/453]\tTrain Loss: 1.730\n",
      "Epoch [6][440/453]\tTrain Loss: 1.729\n",
      "Epoch [6][445/453]\tTrain Loss: 1.728\n",
      "Epoch [6][450/453]\tTrain Loss: 1.728\n",
      "Epoch [6][0/15]\t\t\tValid Loss: 1.731\n",
      "Epoch [6][5/15]\t\t\tValid Loss: 1.725\n",
      "Epoch [6][10/15]\t\t\tValid Loss: 1.721\n",
      "\n",
      "Candidate :▁Ein ▁Mann ▁in ▁Jean s ▁spi elt ▁am ▁Strand ▁mit ▁eine m ▁rot en ▁Ball .\n",
      "Candidate_labeled :  ['<start>', '▁Ein', '▁Mann', '▁in', '▁Jean', 's', '▁spi', 'elt', '▁am', '▁Strand', '▁mit', '▁eine', 'm', '▁rot', 'en', '▁Ball', '.', '</s>']\n",
      "Real :▁Ein ▁Mann ▁in ▁Jean s ▁spi elt ▁an ▁eine m ▁Strand ▁mit ▁eine m ▁rot en ▁Ball .\n",
      "#######   Time elapsed (hh:mm:ss.ms) 0:09:22.173007 #######\n",
      "\n",
      "Epoch [7][0/453]\tTrain Loss: 1.688\n",
      "Epoch [7][5/453]\tTrain Loss: 1.625\n",
      "Epoch [7][10/453]\tTrain Loss: 1.626\n",
      "Epoch [7][15/453]\tTrain Loss: 1.607\n",
      "Epoch [7][20/453]\tTrain Loss: 1.594\n",
      "Epoch [7][25/453]\tTrain Loss: 1.590\n",
      "Epoch [7][30/453]\tTrain Loss: 1.599\n",
      "Epoch [7][35/453]\tTrain Loss: 1.604\n",
      "Epoch [7][40/453]\tTrain Loss: 1.608\n",
      "Epoch [7][45/453]\tTrain Loss: 1.604\n",
      "Epoch [7][50/453]\tTrain Loss: 1.614\n",
      "Epoch [7][55/453]\tTrain Loss: 1.615\n",
      "Epoch [7][60/453]\tTrain Loss: 1.616\n",
      "Epoch [7][65/453]\tTrain Loss: 1.618\n",
      "Epoch [7][70/453]\tTrain Loss: 1.617\n",
      "Epoch [7][75/453]\tTrain Loss: 1.625\n",
      "Epoch [7][80/453]\tTrain Loss: 1.628\n",
      "Epoch [7][85/453]\tTrain Loss: 1.629\n",
      "Epoch [7][90/453]\tTrain Loss: 1.627\n",
      "Epoch [7][95/453]\tTrain Loss: 1.626\n",
      "Epoch [7][100/453]\tTrain Loss: 1.629\n",
      "Epoch [7][105/453]\tTrain Loss: 1.627\n",
      "Epoch [7][110/453]\tTrain Loss: 1.630\n",
      "Epoch [7][115/453]\tTrain Loss: 1.629\n",
      "Epoch [7][120/453]\tTrain Loss: 1.629\n",
      "Epoch [7][125/453]\tTrain Loss: 1.632\n",
      "Epoch [7][130/453]\tTrain Loss: 1.632\n",
      "Epoch [7][135/453]\tTrain Loss: 1.632\n",
      "Epoch [7][140/453]\tTrain Loss: 1.631\n",
      "Epoch [7][145/453]\tTrain Loss: 1.630\n",
      "Epoch [7][150/453]\tTrain Loss: 1.632\n",
      "Epoch [7][155/453]\tTrain Loss: 1.632\n",
      "Epoch [7][160/453]\tTrain Loss: 1.634\n",
      "Epoch [7][165/453]\tTrain Loss: 1.635\n",
      "Epoch [7][170/453]\tTrain Loss: 1.636\n",
      "Epoch [7][175/453]\tTrain Loss: 1.636\n",
      "Epoch [7][180/453]\tTrain Loss: 1.635\n",
      "Epoch [7][185/453]\tTrain Loss: 1.635\n",
      "Epoch [7][190/453]\tTrain Loss: 1.636\n",
      "Epoch [7][195/453]\tTrain Loss: 1.634\n",
      "Epoch [7][200/453]\tTrain Loss: 1.636\n",
      "Epoch [7][205/453]\tTrain Loss: 1.637\n",
      "Epoch [7][210/453]\tTrain Loss: 1.638\n",
      "Epoch [7][215/453]\tTrain Loss: 1.636\n",
      "Epoch [7][220/453]\tTrain Loss: 1.637\n",
      "Epoch [7][225/453]\tTrain Loss: 1.637\n",
      "Epoch [7][230/453]\tTrain Loss: 1.635\n",
      "Epoch [7][235/453]\tTrain Loss: 1.636\n",
      "Epoch [7][240/453]\tTrain Loss: 1.636\n",
      "Epoch [7][245/453]\tTrain Loss: 1.637\n",
      "Epoch [7][250/453]\tTrain Loss: 1.639\n",
      "Epoch [7][255/453]\tTrain Loss: 1.640\n",
      "Epoch [7][260/453]\tTrain Loss: 1.640\n",
      "Epoch [7][265/453]\tTrain Loss: 1.642\n",
      "Epoch [7][270/453]\tTrain Loss: 1.642\n",
      "Epoch [7][275/453]\tTrain Loss: 1.643\n",
      "Epoch [7][280/453]\tTrain Loss: 1.644\n",
      "Epoch [7][285/453]\tTrain Loss: 1.643\n",
      "Epoch [7][290/453]\tTrain Loss: 1.643\n",
      "Epoch [7][295/453]\tTrain Loss: 1.643\n",
      "Epoch [7][300/453]\tTrain Loss: 1.643\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start_time = datetime.now() \n",
    "    train(train_loader, transformer, criterion, epoch)\n",
    "    \n",
    "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    torch.save(state, 'checkpoint_new' + str(epoch+10) + '.pth.tar')\n",
    "    \n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print('#######   Time elapsed (hh:mm:ss.ms) {} #######'.format(time_elapsed))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "heads = 8\n",
    "num_layers = 6\n",
    "num_layers = 6\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "vocab_len = len(tokenizer.get_vocab())\n",
    "\n",
    "transformer = Transformer(d_model = d_model , heads = heads, num_layers = num_layers, vocab_size = vocab_len)\n",
    "transformer = transformer.to(device)\n",
    "# adam_optimizer = torch.optim.Adam(transformer.parameters())\n",
    "# transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(vocab_len, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "# 저장된 파일을 불러올 때\n",
    "checkpoint = torch.load('checkpoint_cross1.pth.tar')\n",
    "\n",
    "# 불러온 checkpoint에서 모델 상태나 다른 필요한 요소들을 추출할 수 있습니다.\n",
    "transformer = deepcopy(checkpoint['transformer'])\n",
    "\n",
    "# 모델을 evaluation 모드로 설정 (필요에 따라)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = {v:k for k,v in tokenizer.get_vocab().items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['<start>'] = 58101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = dict['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(transformer, question, question_mask, max_len, dict):\n",
    "\n",
    "    transformer.eval()\n",
    "\n",
    "    bb = {v:k for k,v in tokenizer.get_vocab().items()} \n",
    "    start_token = 58101\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "    words = torch.LongTensor([[start_token]]).to(device)\n",
    "\n",
    "    for step in range(max_len - 1):\n",
    "        size = words.shape[1]\n",
    "        target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n",
    "        decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
    "        predictions = transformer.logit(decoded[:, -1])\n",
    "    \n",
    "        _, next_word = torch.max(predictions[:,:-1], dim = 1)\n",
    "        print(predictions)       \n",
    "        next_word = next_word.item()\n",
    "  \n",
    "        words = torch.cat([words, torch.LongTensor([[next_word]]).to(device)], dim = 1) \n",
    "\n",
    "\n",
    "    if words.dim() == 2:\n",
    "        words = words.squeeze(0)\n",
    "        words = words.tolist()\n",
    "\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4386,   238,    48,  7288,    32,    14,  6813, 21507,     4,  5542,\n",
       "            3,     0, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
       "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_next_words(transformer, sequence, encoded, question_mask, beam_width):\n",
    "    if not sequence:\n",
    "        return [(start_token, 0)]\n",
    "    \n",
    "    size = len(sequence)\n",
    "    target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "    target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    words = torch.LongTensor([sequence]).to(device)\n",
    "\n",
    "    decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
    "    predictions = transformer.logit(decoded[:, -1])\n",
    "\n",
    "    # Apply log_softmax\n",
    "    log_probs = predictions\n",
    "\n",
    "    # Get top-k words\n",
    "    top_k_probs, top_k_indices = torch.topk(log_probs, beam_width, dim=-1)\n",
    "    top_k_probs = top_k_probs.squeeze().tolist()\n",
    "    top_k_indices = top_k_indices.squeeze().tolist()\n",
    "\n",
    "    next_words = [(word, prob) for word, prob in zip(top_k_indices, top_k_probs)]\n",
    "    return next_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def beam_search(transformer, question, question_mask, max_len, dict, beam_width=5):\n",
    "    transformer.eval()\n",
    "    start_token = 58101\n",
    "    end_token = 58100\n",
    "\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "\n",
    "    beams = [([], 0)] \n",
    "\n",
    "    for step in range(max_len):\n",
    "        candidates = []\n",
    "\n",
    "        for seq, score in beams:\n",
    "            if seq and seq[-1] == end_token:\n",
    "                candidates.append((seq, score))\n",
    "                continue\n",
    "            \n",
    "            next_words = generate_next_words(transformer, seq, encoded, question_mask, beam_width)\n",
    "\n",
    "            for word, log_prob in next_words:\n",
    "                candidates.append((seq + [word], score + log_prob))\n",
    "\n",
    "        # Select top-k candidates\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        beams = candidates[:beam_width]\n",
    "\n",
    "        # Check if all beams have ended\n",
    "        if all(seq[-1] == end_token for seq, _ in beams):\n",
    "            break\n",
    "\n",
    "    best_seq, _ = max(beams, key=lambda x: x[1])\n",
    "    return best_seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58101, 38841, 7858, 28207, 48521, 5163, 7422, 48126, 52802, 51823, 48159, 36367, 19682, 25825, 18527, 4851, 51726, 46066, 141, 35711, 52357, 18822, 54645, 26260, 36463, 25933, 41653, 2056, 296, 44171, 45069, 22527, 19578, 26183, 711, 2724, 1884, 35284, 48126, 15398, 40737, 19682, 25825, 14295, 141, 35711, 52357, 14263, 44054, 53184, 48159, 12456, 31693, 18020, 47823, 48433, 27052, 32682, 36504, 42070, 35261, 48063, 42124, 1777, 53783, 1693, 26183, 711, 2724, 32425, 31765, 49900, 1884, 35284, 48126, 15398, 40737, 19682, 25825, 14295, 141, 35711, 52357, 18822, 14080, 46013, 8900, 33172, 9990, 14295, 141, 35711, 52357, 18822, 14080, 46013, 8900, 33172, 9990, 14295, 141, 35711, 52357, 18822, 14080, 46013, 8900, 33172, 9990, 14295, 141, 35711, 52357, 23123, 27392, 22994, 50631, 25825, 14295, 141, 35711, 52357, 23123, 27392, 22994, 50631, 45864, 32778]\n"
     ]
    }
   ],
   "source": [
    "max_len = 128\n",
    "enc_qus = [  282,   892,   175,    19, 16058,    54,  7288,     5,     4,  3602,\n",
    "            3,     0, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100,\n",
    "        58100, 58100, 58100, 58100, 58100, 58100, 58100, 58100]\n",
    "question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n",
    "question_mask = (question!=58100).to(device).unsqueeze(1).unsqueeze(1)\n",
    "sentence = beam_search(transformer, question, question_mask, int(max_len), dict)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "            True,  True, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False, False, False,\n",
       "           False, False, False, False, False, False, False, False]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feg = []\n",
    "for ww in A.detach().clone().cpu().numpy():\n",
    "    feg_small = []\n",
    "    for www in ww:\n",
    "        if www == 0:\n",
    "            break\n",
    "        else:\n",
    "            feg_small.append(bb[www])\n",
    "        \n",
    "    feg.append(feg_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feg = []\n",
    "for ww in A.detach().clone().cpu().numpy():\n",
    "    feg_small = []\n",
    "    for www in ww:\n",
    "        if www == 0:\n",
    "            break\n",
    "        else:\n",
    "            feg_small.append(bb[www])\n",
    "        \n",
    "    feg.append(feg_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.exp(out.detach().clone()),dim = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fff = [tokenizer.tokenize(i) for i in dataset3['test']['de']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i == j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]d:\\anaconda\\envs\\Pray\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "d:\\anaconda\\envs\\Pray\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "d:\\anaconda\\envs\\Pray\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "960it [00:01, 658.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "scores = []\n",
    "for i,j in tqdm(zip(feg, fff)):\n",
    "    score1 = corpus_bleu(i, j)\n",
    "    scores.append(score1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
